dolphin-2.2.1-mistral-7b: # should be the same as the name as the current directory
  prompt_template: null # ideally we should have a prompt as documentation
  fn_completions: null # wasn't generated by alpaca_eval but could be "huggingface_local_completions"
  completions_kwargs: # ideally should fill some decoding parameters as documentation
    # max_length: 1024
    # temperature: 0.8
  pretty_name: "Dolphin 2.2.1 7B" # name as will be shown in the leaderboard
  link: "https://huggingface.co/cognitivecomputations/dolphin-2.2.1-mistral-7b" # link to the model's repo

