{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4f80ae-d4bf-48f0-802b-a932de6c9759",
   "metadata": {},
   "source": [
    "# Length controlled AlpacaEval\n",
    "\n",
    "This notebook is about trying to correct for the length bias in AlpacaEval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e923ce-1f87-4c6c-87f3-70c0bca767b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yanndubois/Desktop/GitHub/alpaca_eval\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406fc95c-073a-4952-818b-712ceac94c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3ad57-504d-4460-a489-113c0082f3cf",
   "metadata": {},
   "source": [
    "## Desiderata?\n",
    "\n",
    "Here are the desired properties that we would like for our length-corrected win-rate.\n",
    "\n",
    "Here are the things that I think we should be considering when deciding\n",
    "1. **(D1) Have high correlation with humans** ultimately the most important property for AlpacaEval is that it's highly correlated with humans. Arguably this is a property that we already have, so we should just make sure that the correlation of the length-corrected win-rate is at least as high, and ideally higher than the current correlation. Note that we have high-correlations with human despite the length bias because (1) humans are also length-biased; and (2) we have validated our auto-annotators compared to humans only in standard/realistic scenario rather than in extreme/\"worst-case\" ones. This brings us to D2.\n",
    "2. **(D2) Low length gameability** one major issue with a bias metric is that adversarial players may take advantage of it, i.e., game the metric. This might not be seen when looking at standard correlation with humans because we rarely test gamed systems. Given that correlation with humans is already very high (D1), we see (D2) as the major new property that we are trying to achieve. We would thus ideally want gamed systems (e.g. by changing the system prompt to be verbose) to not change too much. Note that humans might not actually have such property, so we are asking more from our auto-annotators than humans. \n",
    "This is nevertheless very important for a leaderboard like AlpacaEval, because people usually think about it as an evalaution of a model rather than a system (model+prompt). We thus want to avoid having large prompt gameability so that it behaves closer to what people have in mind. \n",
    "3. **(D3) Similar length bias as humans**: human are typically length biased, the goal is thus not to be length-invariant but to match human biases. \n",
    "4. **(D4) Simplicity**: the model length correction should be simple enough for people to understand what is happening and what are limitations of the length corrections. Let's not hide the limitations (and potential gameability) behind complexity.\n",
    "5. **(D5) Similar interpretation as win-rate**: given that we'll use for the default AE metric, we would like the interpretation of the result to be as similar as  possible as the non-bias corrected ones given that people are used to those. I.e. preference for having 50% for the baseline, the range being between 0-100, ...\n",
    "6. **(D6) General procedure**: although length-bias is the biggest issue, AlpacaEval has other biases (e.g. bias towards lists, bias towards outputs similar to those from the autoannotator, ...). We thus like a general procedure to deal with biases so that we can reuse it when needed, and others can use simialr procedures for their benchmark.\n",
    "7. **(D7) Robustness**: we want to avoid as much as possible having settings in which the length-corrected metric can be gamed in a different way. E.g. by generating extremely short answers.\n",
    "8. **(D8) Independence between models**: as much as possible we would like our correction to not depend on the outputs / values / ranking of other models. In particular, we want the length-corrected metric to not have to be updated when future models (e.g. that are very long) are developed.\n",
    "\n",
    "In addition to the aforementioned desired properties, we have a hard constraint that there should be **no reevaluation needed**. I.e., the new metric should be a function of what we currently have to ensure that we can port the leaderboard.\n",
    "\n",
    "Now let's check how to decide whether a method is better or worse, i.e., what metrics to consider for the rest of the notebook.\n",
    "\n",
    "## Metrics?\n",
    "\n",
    "Stratified arena correlation per length. Per output.\n",
    "\n",
    "Here are the metrics I think we should be considering, one for each of the three desiderata.\n",
    "\n",
    "- **(D1) High Spearman correlation with Chatbot Arena Leaderboard.** This is the most important, and Chatbot arena as source of human truth given that it's the only large scale and in-the-wild chat leaderboard based on human data. The question then becomes which correlations. Given that ELO and win rate are very different metrics (e.g. one is bounded and not the other) there's no reason to hope that linear correlation holds, so we shouldn't use Pearson. More importantly, we only care about relative values with a benchmark like AlpacaEval (the usecase being model selection) so non-parametric correlation is better suited. Note that the choice of Spearman vs Kendall doesn't matter much here, we will use Spearman because it's on \"the same scale\" as Pearson correlation which people are more used to (e.g. Kendall is much smaller which always surprises people because they are not used to interpreting it). Also note that when using non-parametric correlations it's extremely important to fix the number of points you are comparing, otherwise more points always looks better. \n",
    "\n",
    "  \n",
    "- **(D2) Small relative variance when prompting for verbosity/conciseness.** One heuristic to avoid gameability is to ensure that the win-rate for a model is close to the win-rate of the same model prompted for verbosity. To test that we will use a few models and prompt them (1) normally, (2) to \"give as much detail as possible\", (3) to \"be as concise as possible while still providing all the necessary information to answer the question\". Then we will look at the variance between those three, which ideally shouldn't be too large. We will use GPT4-turbo, Claude 2, GPT3-turbo, GPT4, Mixtral. In particular, we will consider the relative standard deviation. Standard deviation, simply because it's easier to interpret. Relative in the sense that we (1) normalize by the non-gamed win rate, and (2) we normalize by the standard deviation of different models, i.e., squishing the range of the metric shouldn't solve the gameability issue. Note that ideally, we would actually estimate the gameability of humans and be able to compare to that. Unfortunately LMSys doesn't evaluate the same model with different prompts. @todo: ask them.\n",
    "\n",
    "- **(D2') Robustness to white-box adversarial attacks.** One issue when corecting for length is that we introduce a very direct method to change win-rate, which opens up issues of potential white-box adversarial attacks. Where people submitting to the benchmark might postprocess the outputs in such a way that our correction makes it seem better. THis is not a major concern to me given that I see the most important usecase of AlpacaEval for development, rather than for the leaderboard. But to make sure that people trust AE enough to use it for development, we unfortunatley have to think about those. One adversarial attack postprocessing of outputs that attacks most of the methods we considered, is to have prosprocess the outputs in such a way that most are short and not preferred by AE (e.g. by truncation) but that all the ones that are longer than the baseline are preferred => many length correction methods will think that the model would be better with longer outputs. The issue here is that outputs would not be sampled idnependently of the anntoations. These adversarial attacks are very hard to avoid but we still keep track of them. In particular I postprocess GPT4 outputs in `gpt4_gamed` to do exactly this. We will keep track of the increase in win-rate and ranking of this adversarial model.\n",
    " \n",
    "- **(D3) Same Spearman correlation AE-Length as Arena-Length.** To track the length bias of humans we can see how correlated the Arena leaderboard is with a leaderboard that simply ranks outputs by their lengths. Again we use Spearman correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f21ede-eef2-4cd1-a5cd-c0e76be7d143",
   "metadata": {},
   "source": [
    "## Setting up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4760f6-fd06-4d2c-bced-f0bc0f63c4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanndubois/opt/anaconda3/envs/alpaca_eval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from alpaca_eval import utils, metrics, annotators, constants, analyze, plotting, main\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer, accuracy_score, log_loss as sk_log_loss\n",
    "from notebooks.notebook_helpers import get_chatbot_arena_lb_mapping, print_correlations, make_data, logit, load_annotations\n",
    "\n",
    "sklearn.set_config(enable_metadata_routing=True)\n",
    "\n",
    "BASELINE = \"gpt4_1106_preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953043d0-d527-4717-bd89-0971b1d39211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are comparing to 38 Arena models\n"
     ]
    }
   ],
   "source": [
    "lb = pd.read_csv(\"src/alpaca_eval/leaderboards/data_AlpacaEval_2/weighted_alpaca_eval_gpt4_turbo_leaderboard.csv\", index_col=0)#.query(\"index != 'gpt4_gamed'\")\n",
    "\n",
    "dict_arena = get_chatbot_arena_lb_mapping()\n",
    "\n",
    "def make_lb_arena(lb):    \n",
    "    lb_arena = lb.loc[list(dict_arena.keys()),:]\n",
    "    lb_arena[\"ELO\"] = dict_arena.values()\n",
    "    return lb_arena\n",
    "\n",
    "lb_arena = make_lb_arena(lb)\n",
    "print(f\"We are comparing to {len(lb_arena)} Arena models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb37f4f-7636-4dd2-9230-9a3b39cf2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_process_v = lambda s : s.replace(\"_verbose\",\"\")\n",
    "game_process_c = lambda s : s.replace(\"_concise\",\"\")\n",
    "gamed_models = [i for i in lb.index\n",
    "               if (i + \"_verbose\") in lb.index and (i + \"_concise\") in lb.index]\n",
    "diff_models = [i for i in lb.index if \"_verbose\" not in i and i + \"_concise\" not in i]\n",
    "lb[\"gamed_verbose_only\"] = [game_process_v(i) if game_process_v(i) in gamed_models else None for i in lb.index]\n",
    "lb[\"gamed_concise_only\"] = [game_process_c(i) if game_process_c(i) in gamed_models else None for i in lb.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e353f-6edc-480c-9be1-d8c07ce3c110",
   "metadata": {},
   "source": [
    "Here are the models that we gamed (i.e. prompted for verbosity/conciseness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b341e73-e391-416c-96af-7d6f50612c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt4_1106_preview',\n",
       " 'gpt4_0613',\n",
       " 'claude-2.1',\n",
       " 'Mixtral-8x7B-Instruct-v0.1',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'alpaca-7b']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamed_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99ccfe5-4e0f-406a-9d2d-62599c9e3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def report(lb, metric, is_detailed=False, n_toshow=10, is_return_metrics=False):\n",
    "    lb_arena = make_lb_arena(lb)\n",
    "\n",
    "    if not is_return_metrics:\n",
    "        print(f\"# Report for **{metric}**\")\n",
    "\n",
    "        print()\n",
    "        print(\"## Gameability (lower is better)\")\n",
    "\n",
    "    df_gamed_v = lb.groupby(\"gamed_verbose_only\")[[\"avg_length\", metric]].agg([\"mean\",\"std\"]) \n",
    "    df_gamed_c = lb.groupby(\"gamed_concise_only\")[[\"avg_length\", metric]].agg([\"mean\",\"std\"]) \n",
    "    # relative in the sense that models with larger metric shouldn't be considered as having larger vairance\n",
    "    df_gamed_v[(metric, 'rel_std')] = df_gamed_v[metric][\"std\"] /  df_gamed_v[metric][\"mean\"]\n",
    "    df_gamed_c[(metric, 'rel_std')] = df_gamed_c[metric][\"std\"] /  df_gamed_c[metric][\"mean\"] \n",
    "    # renormalize to avoid removing gameability by shrinking the scale of the metric\n",
    "    winrate_std_across_models = lb[lb.index.isin(diff_models)][\"win_rate\"].std()\n",
    "    metric_std_across_models = lb[lb.index.isin(diff_models)][metric].std()\n",
    "    metric_weight = winrate_std_across_models / metric_std_across_models \n",
    "    \n",
    "    if is_detailed:\n",
    "        print(f\"metric_weight: {metric_weight:.3f}\")\n",
    "        display(df_gamed_v)\n",
    "        display(df_gamed_c)\n",
    "\n",
    "    verbosity_gameability = df_gamed_v[metric]['rel_std'].mean() * metric_weight * 100\n",
    "    conciseness_gameability = df_gamed_c[metric]['rel_std'].mean() * metric_weight * 100\n",
    "\n",
    "    adversarial_winrate_gain = lb.loc[\"gpt4_gamed\",metric] - lb.loc[\"gpt4_gamed\",\"win_rate\"]\n",
    "\n",
    "    rank_by_metric = lb[metric].rank(method='min', ascending=False)  # Adjust ascending as needed\n",
    "    rank_by_win_rate = lb['win_rate'].rank(method='min', ascending=False)  # Adjust ascending as needed\n",
    "    adversarial_rank_gain = rank_by_win_rate.loc[\"gpt4_gamed\"] - rank_by_metric.loc[\"gpt4_gamed\"]\n",
    "    \n",
    "    if not is_return_metrics:\n",
    "        print(f\"Verbosity gameability (relative std metric): {verbosity_gameability:.1f}%\")\n",
    "        print(f\"Conciseness gameability (relative std metric): {conciseness_gameability:.1f}%\")\n",
    "        print(f\"Adversarial winrate gain: {adversarial_winrate_gain:.1f}\")\n",
    "        print(f\"Adversarial rank gain: {adversarial_rank_gain}\")\n",
    "\n",
    "        print()\n",
    "        print(\"## Correlation with Arena (higher is better)\")\n",
    "\n",
    "    corr_arena = print_correlations(lb_arena[metric], lb_arena[\"ELO\"], is_return_metrics=is_return_metrics)\n",
    "\n",
    "    \n",
    "    if not is_return_metrics:\n",
    "        print()\n",
    "        arena_corr = print_correlations(lb_arena[\"ELO\"],\n",
    "                                       lb_arena[\"avg_length\"],\n",
    "                                        \"Arena vs Length\", \n",
    "                                        is_return_metrics=True)\n",
    "\n",
    "        \n",
    "        print(f\"## Correlation with length (closer to spearman={arena_corr['spearman']:.2f}, kendall={arena_corr['kendall']:.2f} is better)\")\n",
    "    \n",
    "    corr_len = print_correlations(lb_arena[metric], lb_arena[\"avg_length\"], is_return_metrics=is_return_metrics)\n",
    "\n",
    "    if not is_return_metrics:\n",
    "        print()\n",
    "        print(f\"## Top {n_toshow} models\")\n",
    "    \n",
    "        display(lb[metric].sort_values(ascending=False)[:n_toshow])\n",
    "    \n",
    "        print()\n",
    "        print(f\"## Bottom {n_toshow} models\")\n",
    "    \n",
    "        display(lb[metric].sort_values(ascending=False)[-n_toshow:])\n",
    "\n",
    "    if is_return_metrics:\n",
    "        return dict(verbosity_gameability=verbosity_gameability, \n",
    "                    conciseness_gameability=conciseness_gameability,\n",
    "                    adversarial_rank_gain=adversarial_rank_gain,\n",
    "                    adversarial_winrate_gain=adversarial_winrate_gain,\n",
    "                   corr_arena=corr_arena[\"spearman\"],\n",
    "                    corr_len=corr_len[\"spearman\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ddf6f-d338-4703-a89a-a24686922f03",
   "metadata": {},
   "source": [
    "Here are the correlations between Arena and length that we should try to be close to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2dee0d-b579-4b91-a55c-503c6e1192e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arena vs Length\n",
      "Spearman Corr: 0.349\n",
      "Kendall Corr: 0.248\n"
     ]
    }
   ],
   "source": [
    "print_correlations(lb_arena[\"ELO\"],\n",
    "                   lb_arena[\"avg_length\"],\n",
    "                  \"Arena vs Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821ff4c-1e7b-4970-ac5d-028b5945d5c0",
   "metadata": {},
   "source": [
    "## Raw win rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c03e2-ef7c-4588-baef-028c8b96280e",
   "metadata": {},
   "source": [
    "- **What**: compute the expected number of times that the model is better than the baseline. This is the default in AE.\n",
    "- **Benefits**: simple\n",
    "- **Downside**: length bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f772b9-8ee7-470c-a9ac-4027fbf978d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Report for **win_rate**\n",
      "\n",
      "## Gameability (lower is better)\n",
      "Verbosity gameability (relative std metric): 21.3%\n",
      "Conciseness gameability (relative std metric): 29.8%\n",
      "Adversarial winrate gain: 0.0\n",
      "Adversarial rank gain: 0.0\n",
      "\n",
      "## Correlation with Arena (higher is better)\n",
      "Spearman Corr: 0.936\n",
      "Kendall Corr: 0.825\n",
      "\n",
      "## Correlation with length (closer to spearman=0.35, kendall=0.25 is better)\n",
      "Spearman Corr: 0.497\n",
      "Kendall Corr: 0.362\n",
      "\n",
      "## Top 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gpt4_1106_preview_verbose                64.303601\n",
       "gpt4_1106_preview                        50.000000\n",
       "Snorkel-Mistral-PairRM-DPO-best-of-16    34.860133\n",
       "Contextual-KTO-Mistral-PairRM            33.227355\n",
       "pairrm-Yi-34B-Chat                       31.241283\n",
       "Snorkel-Mistral-PairRM-DPO               30.220053\n",
       "Yi-34B-Chat                              29.659947\n",
       "claude-3-opus-20240229                   29.041764\n",
       "Samba-CoE-v0.2-best-of-16                26.988254\n",
       "Qwen1.5-72B-Chat                         26.498283\n",
       "Name: win_rate, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Bottom 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "guanaco-7b              2.880002\n",
       "text_davinci_001        2.764005\n",
       "chatglm2-6b             2.762185\n",
       "alpaca-7b               2.591451\n",
       "pythia-12b-mix-sft      2.578090\n",
       "phi-2                   2.350210\n",
       "falcon-7b-instruct      2.146618\n",
       "baichuan-13b-chat       1.992146\n",
       "alpaca-7b_concise       1.991176\n",
       "oasst-sft-pythia-12b    1.790114\n",
       "Name: win_rate, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(lb, \"win_rate\", is_detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a696a1c4-d342-4bb2-825f-e8b3bac4f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_metrics = report(lb, \"win_rate\", is_detailed=False, is_return_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98342d-ccc8-47b5-953f-6231954dc601",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- gameability due to asking for details is high\n",
    "- correlation with Arena is relatively high\n",
    "- correlation with length is >2x than Arena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abd80b-a4a9-4d79-8013-8b9a6518f07e",
   "metadata": {},
   "source": [
    "# Proposed new metric: Length-controlled win-rate\n",
    "\n",
    "First, let's compute some values---based on annotations---that will be useful for all the proposed metrics. Note throughout the rest that 1 -> baseline, and 2 -> model being evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72d9e839-f561-40f4-82c0-30d058c0cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_annotations = load_annotations(lb)\n",
    "all_df_annotations = all_df_annotations.query(\"len_2 != 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac6673-796a-4761-b6a0-fa4320eb5d91",
   "metadata": {},
   "source": [
    "\n",
    "## Causal inference and mediated effect: length-controlled win-rate\n",
    "\n",
    "**Background**: one extreme intepretation of a length-corrected metric, is the answer to \"what would be the metrics if all models had the same length as the baseline\". This enters the relm of causal inference where we are asking ourselves \"what is the direct impact of the model generating the output\". In particular, we don't want to consider the impact through \"bias\" variable such as length. Such variables are called mediators. Note that we don't want to rerun anything so we have to use techniques from causal inference for observational data.\n",
    "\n",
    "Here's the graphical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7487b20-5282-4d0b-9291-8d41f9049694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"648pt\" height=\"190pt\"\n",
       " viewBox=\"0.00 0.00 648.37 190.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 186)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-186 644.37,-186 644.37,4 -4,4\"/>\n",
       "<!-- M -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>M</title>\n",
       "<ellipse fill=\"green\" stroke=\"black\" cx=\"230.75\" cy=\"-164\" rx=\"35.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"230.75\" y=\"-158.95\" font-family=\"Times,serif\" font-size=\"14.00\">Model</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"red\" stroke=\"black\" cx=\"68.75\" cy=\"-91\" rx=\"68.75\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"68.75\" y=\"-85.95\" font-family=\"Times,serif\" font-size=\"14.00\">Other Mediator</text>\n",
       "</g>\n",
       "<!-- M&#45;&gt;B -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>M&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M204.36,-151.43C179.66,-140.61 142.28,-124.22 113.01,-111.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.6,-107.83 104.03,-107.02 111.79,-114.24 114.6,-107.83\"/>\n",
       "</g>\n",
       "<!-- L -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>L</title>\n",
       "<ellipse fill=\"red\" stroke=\"black\" cx=\"230.75\" cy=\"-91\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"230.75\" y=\"-85.95\" font-family=\"Times,serif\" font-size=\"14.00\">Length of Output</text>\n",
       "</g>\n",
       "<!-- M&#45;&gt;L -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>M&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.75,-145.81C230.75,-138.05 230.75,-128.68 230.75,-119.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"234.25,-120.03 230.75,-110.03 227.25,-120.03 234.25,-120.03\"/>\n",
       "</g>\n",
       "<!-- S -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>S</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"313.75\" cy=\"-18\" rx=\"43.67\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"313.75\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Win&#45;rate</text>\n",
       "</g>\n",
       "<!-- M&#45;&gt;S -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>M&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M259.29,-153.09C278.75,-144.66 303.04,-130.46 314.75,-109 325.05,-90.15 324,-65.59 320.82,-46.89\"/>\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"324.05,-46.22 318.65,-37.11 317.19,-47.6 324.05,-46.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"379.25\" y=\"-85.95\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"green\"> &#160;Desired interaction</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;S -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.69,-76.98C157.59,-64.26 224.07,-44.99 268.19,-32.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.99,-35.33 277.62,-29.18 267.04,-28.6 268.99,-35.33\"/>\n",
       "</g>\n",
       "<!-- L&#45;&gt;S -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>L&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M250.42,-73.17C261.38,-63.8 275.17,-52 287.09,-41.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.04,-43.89 294.36,-34.73 284.49,-38.57 289.04,-43.89\"/>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"lightgray\" stroke=\"black\" cx=\"555.75\" cy=\"-91\" rx=\"84.62\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"555.75\" y=\"-85.95\" font-family=\"Times,serif\" font-size=\"14.00\">Instruction (data: x)</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;S -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>I&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M507.36,-75.8C464.22,-63.15 401.54,-44.75 359.29,-32.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"360.32,-28.72 349.74,-29.27 358.35,-35.44 360.32,-28.72\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x15eeaa1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from graphviz import Digraph\n",
    "    dot = Digraph()\n",
    "    dot.node('M', 'Model', style='filled',fillcolor=\"green\")\n",
    "    dot.node('B', 'Other Mediator', style='filled', fillcolor=\"red\",)\n",
    "    dot.node('L', 'Length of Output', style='filled', fillcolor=\"red\",)\n",
    "    dot.node('I', 'Instruction (data: x)', style='filled', fillcolor=\"lightgray\")\n",
    "    dot.node('S', 'Win-rate')\n",
    "    dot.edge('M', 'L')\n",
    "    dot.edge('M', 'B')\n",
    "    dot.edge('B', 'S')\n",
    "    dot.edge('L', 'S')\n",
    "    dot.edge('I', 'S')\n",
    "    dot.edge('M', 'S', \"  Desired interaction\", color=\"green\", fontcolor=\"green\")\n",
    "    dot.render('causal_graph', format='png', cleanup=True)\n",
    "    display(dot)\n",
    "except ImportError:\n",
    "    from IPython.display import Image\n",
    "    Image(filename=\"notebooks/causal_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87764e-0aa9-4bfa-bf76-87e06e8c2080",
   "metadata": {},
   "source": [
    "The benefit of taking such perspective is that:\n",
    "1. it gives us a very general way of dealing with \"biases\"/mediators we do not want to consider (in our case, length, but this can be any mediator).\n",
    "2. this is well studied, and a very common approach to dealing with simialr problems to ours (e.g. in social sciences, clinical studies, econometrics, ...)\n",
    "\n",
    "So all we need is to write a reasonable (generalized) **linear structural equation** that conditions on:\n",
    "- undesirable mediators (red above) => condition on covariate you don't want to consider. We will later set those to the same as the baseline model.\n",
    "- on the treatment (green above) => measure the actual interaction you care about.\n",
    "\n",
    "We use the following which has many nice properties. I discuss how we came to that function form at the end if you are interested:\n",
    "\n",
    "$$win\\_rate(m,b) = \\frac{1}{N} \\sum_{i=1}^{N} logistic( \\mathbf{w}_l[(m,b)]  * tanh(standardized(length(m(x_i)) - length(b(x_i)))) + (w_{x}[m] - w_{x}[b]) * embedding(x_i)  + (\\mathbf{w}_m[m] - \\mathbf{w}_m[b]))$$\n",
    "\n",
    "Where $C()$ one hot-encodes, $embedding$ embeds the example to a scalar, $\\mathbf{w}_*|w_*$ are respectively is a vector|scalar of trainable weights, $^T \\cdot$ is dot product, $m$ is the model, $b$ is the baseline, $x$ is the instruction, $m(x)$ is the output by model `m`. \n",
    "\n",
    "**Notes and nice properties:**\n",
    "- *simplifications*: we always train with the same baseline so we can optimize instead for $w'_{x}[m] = (w_{x}[m] - w_{x}[b])$ and $\\mathbf{w}'_m[m] = (\\mathbf{w}_m[m] - \\mathbf{w}_m[b])$ so the problem becomes:\n",
    "$$win\\_rate(m,b) = \\frac{1}{N} \\sum_{i=1}^{N} logistic(\\mathbf{w}'_l[m] * tanh(length(m(x_i)) - length(b(x_i))) + w'_{x}[m] * embedding(x_i)  + \\mathbf{w}'_m[m]) $$\n",
    "- *win\\_rate(m,b) = 1 - win\\_rate(b,m)* as expected. This is an important property for (length controlled) win rates to be keep the same interpretation. This can be seen by the fact that each term consists of an antisymmetric function of a difference between the baseline and the model. Furthermore, the logistic function has the nice property that `logistic(-x) = 1 - logistic(x)`.\n",
    "- *win\\_rate(b,b) = 0.5* the win rate of a baseline is always 0.5 (implied by rpevious property) because we always have $mean(logistic(0)) = 0.5$. Note that is why we don't add a bias term.\n",
    "- *no length correction when same length*: `standardized` here doesn't center, so if the length of two outputs are the same we always have $tanh(standardized(length(m(x_i)) - length(b(x_i))))=0$ meaning that we don't correct for length (as desired).\n",
    "- *monotonicity*: `tanh` is monotonic and bounded => larger differences of lengths will yield larger controlled-win rates but with diminishing returns.\n",
    "- *easily extendible*: it is very easy to add new mediators when we want to cotrol for those. All we need is to add an additive term of the form $f(m,b;x,W)$ where $f$ is antisymmetric (i.e. $f(m,b;x,W)=-f(m,b;x,W)$, linear in weights (i.e., $W[(m,b)] @ g(m,b;x)$ for some $g$ and where `@` is some linear operator such as dot product, matrix multiplication, ... ) and satisfies desired properties for the mediator. E.g. if we want to control for the fact that GPT4 prefers it's outputs we can simply add an additive term $is\\_my\\_output(b) - is\\_my\\_output(m)$ that checks whether the anntotator exhibits some bias for one model but not the other (it could also be continuous, if there was a continuous notion of similarity).\n",
    "- *can predict any baseline* although not necessarily useful, we can naturally predict the win-rate between any two models once we fit the linear model (even if we fitted $w'$ isntead of $w$). Indeed, all we need is to use the initial equation with difference of parameters and replace $w$ with $w'$. This is because $w'[m] = w[m] - w[b]$ so $w'[m] - w'[n] = w[m] - w[b] - (w[n] - w[b]) = w[m] - w[n]$.\n",
    "- *arbitrary tanh and standardization*. I used those because I wanted (1) an antysymmetric function, (2) centered around 0, (3) monotnic, (4) that changes enough with the difference of lengths, and (4) that has as few parameters as possible. You can use normal cdf - 0.5, a temperature scaled logistic - 0.5, a symlog,  ... they all give similar results.\n",
    "\n",
    "Note that the interpretation of $embedding$ is that we want to simulate the fact that some models might be better than others on specific examples. The embedding is a scallar for each example that is trained accross all models. Intuitively if its absolue value is large then it means that the distribution of preference for that example is more spiky, i.e., there's more often a clear winner. From a stats point of view it's typical to condition your linear structural equations on any independent variable (gray in the causal model) that matters but is neither a mediator nor a treatment. The instruction is such a varaible, and we thus want to condition the GLM on the instruction. A simple way to do that, would be to add as feature the one hot encoding of the instruction. The problem is that for each model we only have one have one example per instruction, so if we were to fit $\\mathrm{W}_x[m]^T C(x_i)$ we would be able to perfectly predict any example by setting $\\mathrm{W}_x[m,i] = exp(y_i)$. So we have to embed the instruction to decrease the capacity of the model. We do so by jointly fitting a scalar weight for each example. Another option would be to take some higher dimension embedding (e.g. from an LLM) although if the dimensionality is more than the number of examples that could cause the same issues as $C(x_i)$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a99823-8197-44a1-8b69-48d2050ed569",
   "metadata": {},
   "source": [
    "- **What**: fit a logistic between instruction / length / model -> win_rate. This will be estimate to give the direct effect of the model on the win_rate, while conditioning away the effect of mediators. We could then use $\\mathbf{w}_m[m]$ as a length-controlled metric, but given that we want the metric to still be interpreted on the same scale as the previous win rate, we will instead set the mediators to the values from the baseline (i.e. same length of output). This can then essentially be thought of as \"what would be the win-rate if the model's outputs were the same length as the baseline ones\" (actual causal conclusions would need more care).\n",
    "- **Benefits**:\n",
    "    - **(D1-D3) metrics**: much better in all metrics than raw win-rate, even better than the two previous ones.\n",
    "    - standard: standard analysis for controlling covariates.\n",
    "    - **(D5) ~interpretability**: similar interpretation as win-rate and same scale. Especially since $win\\_rate(m,b) = 1 - win\\_rate(b,m)$\n",
    "    - **(D6) generality**: the procedure is extremely general, e.g., if we wanted to control for the amount of lists we could jsut throw that as a covariate. Furthermore, this is the ~likely the best things to do from a statistical point of view (assuming you don't have enough examples for propensity score matching) => giving the right example for other benchmarks.\n",
    "    - **(D7) robustness**: compared to the two previous examples this method is robust for whatever lengths of enw models, given that the parameters&binning will be fitted on the new models independently of the the previous ones.\n",
    "    - **(D8) ~independence**: the only parameters that need to be fitted across models is $\\mathbf{w}_x^T$, which can be thought of as \"the difficulty\" of the current example. Given that we already have 120 examples for each of those parameters, we can fit them nwo and hold those constants for new models. Conditioned on those parameter, we will be able to control the lengths for new models independently of other models => no need to recompute the rankings.\n",
    "    - Nice properties: e.g. can predict the win rate between any pairs of models.\n",
    "- **Downside**:\n",
    "    - ~interpretability: although regression analysis for conrolling covaraites is common in stats, it might nto be as natural for some of the NLP / LLM-enthousiast community\n",
    "    - functional form: although pretty standard and satisfies many nice properties, it's not clear that it's the \"correct\" functional form.\n",
    "    - **(D4) simplicity**: the procedure is more involved than for previous metrics, which will make it harder for people to understand and might decrease the use of it. \n",
    "\n",
    "Overall, I think this is the best option we have, but I do worry about the fact that it makes the metric harder to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d206b11-35ad-4113-8a64-cf2b100865fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca_eval.metrics.glm_winrate import make_dmatrix_for_model, fit_LogisticRegressionCV, logloss\n",
    "    \n",
    "def regression_report(y_true, y_pred):\n",
    "    return dict(\n",
    "        logloss = logloss(y_true, y_pred),\n",
    "        mse=mean_squared_error(y_true, y_pred) ,\n",
    "        r2=r2_score(y_true, y_pred),\n",
    "        corr=pearsonr(y_true, y_pred).statistic,\n",
    "        acc=accuracy_score(np.round(y_true).astype(int), np.round(y_pred).astype(int))\n",
    "    )\n",
    "\n",
    "\n",
    "            \n",
    "def disjoint_optimization_(df, df_lb, formula, regularize_to_baseline_lambda = None, **kwargs):\n",
    "    all_reports = dict()\n",
    "    all_models = dict()\n",
    "    curr_df_lb = df_lb.copy()\n",
    "    \n",
    "    for m in df[\"generator_2\"].unique():\n",
    "        df_gamed = df.query(f\"~`not_gamed_baseline`\")\n",
    "        df_m = df.query(f\"`generator_2` == '{m}'\").copy()\n",
    "        df_m[\"not_gamed_baseline\"] = True # need to reset in case the current is gamed\n",
    "        df_gamed_and_m = pd.concat([df_gamed, df_m], axis=0)\n",
    "        curr_df_lb_m = curr_df_lb.query(f\"`generator_2` == '{m}'\")\n",
    "        df_input, df_input_lb = make_dmatrix_for_model(df_gamed_and_m, curr_df_lb_m, formula=formula)\n",
    "        \n",
    "        df_input_only_m = df_input[df_gamed_and_m[\"not_gamed_baseline\"]]\n",
    "\n",
    "        if regularize_to_baseline_lambda:\n",
    "            # divided by 2 becasue there are two gamed baselines. \n",
    "            sample_weight = (df_gamed_and_m[\"not_gamed_baseline\"]).astype(float) + (regularize_to_baseline_lambda * (~df_gamed_and_m[\"not_gamed_baseline\"])).astype(float) / 2\n",
    "        else:    \n",
    "            sample_weight = None\n",
    "            df_input = df_input_only_m\n",
    "\n",
    "        model = fit_LogisticRegressionCV(df_input, \"preference\", is_ytrue_proba=True, n_splits=5, sample_weight=sample_weight, **kwargs)\n",
    "\n",
    "        if m == BASELINE:\n",
    "            # by definition (we shoudln't actually fit it, there's one dof too much)\n",
    "            model.coef_ *= 0\n",
    "        \n",
    "        all_models[m] = model\n",
    "\n",
    "        all_reports[m] = regression_report(df_input_only_m[\"preference\"], \n",
    "                                           model.predict_proba(df_input_only_m.drop(columns=[\"preference\"]))[:,1])\n",
    "        curr_df_lb.loc[curr_df_lb[\"generator_2\"] == m, \"preference\"] = model.predict_proba(df_input_lb)[:,1]\n",
    "        \n",
    "    lb[formula] = curr_df_lb.groupby(\"generator_2\")[\"preference\"].mean()[lb.index] * 100\n",
    "    metrics = report(lb, formula, is_return_metrics=True)\n",
    "    metrics.update(pd.DataFrame(all_reports).T.mean().to_dict())\n",
    "    return metrics, all_models  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33839356-e4cf-4e05-9e64-1584040adc23",
   "metadata": {},
   "source": [
    "First, let's load the instruction complexity ($\\mathbf{w'}_x^T$) which I precomputed by joint fitting across all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1768858-497f-490f-8be5-8d2fdf41f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "out = hf_hub_download(repo_id=\"tatsu-lab/alpaca_eval\", \n",
    "                filename=\"instruction_difficulty.csv\",\n",
    "                repo_type=\"dataset\",\n",
    "                cache_dir=constants.DEFAULT_CACHE_DIR)\n",
    "               \n",
    "instruction_difficulty = pd.read_csv(out, index_col=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b3f3460-ba69-4994-91c6-19f4931f334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanndubois/opt/anaconda3/envs/alpaca_eval/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 261 ms, total: 17.8 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "formula=\"np.tanh(rand_delta_len_std_only) + instruction_difficulty + not_gamed_baseline.astype(float) - 1\"\n",
    "\n",
    "# df_lb contains the covariate that are held the same as the baseline \n",
    "df, df_lb = make_data(all_df_annotations, instruction_difficulty=instruction_difficulty)\n",
    "\n",
    "# run the disjoint optimization for all models.\n",
    "metrics, models = disjoint_optimization_(df, df_lb, formula=formula, regularize_to_baseline_lambda=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f7e0236-9115-4c50-b214-82faa6be7c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Report for **np.tanh(rand_delta_len_std_only) + instruction_difficulty + not_gamed_baseline.astype(float) - 1**\n",
      "\n",
      "## Gameability (lower is better)\n",
      "Verbosity gameability (relative std metric): 6.4%\n",
      "Conciseness gameability (relative std metric): 13.6%\n",
      "Adversarial winrate gain: 8.5\n",
      "Adversarial rank gain: 45.0\n",
      "\n",
      "## Correlation with Arena (higher is better)\n",
      "Spearman Corr: 0.977\n",
      "Kendall Corr: 0.876\n",
      "\n",
      "## Correlation with length (closer to spearman=0.35, kendall=0.25 is better)\n",
      "Spearman Corr: 0.327\n",
      "Kendall Corr: 0.222\n",
      "\n",
      "## Top 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gpt4_1106_preview_verbose    51.575008\n",
       "gpt4_1106_preview            50.000000\n",
       "gpt4_1106_preview_concise    41.896602\n",
       "claude-3-opus-20240229       40.391776\n",
       "gpt4                         38.128090\n",
       "Qwen1.5-72B-Chat             36.571754\n",
       "gpt4_0314                    35.307061\n",
       "claude-3-sonnet-20240229     34.872474\n",
       "gpt4_0613_verbose            33.821267\n",
       "mistral-large-2402           32.652080\n",
       "Name: np.tanh(rand_delta_len_std_only) + instruction_difficulty + not_gamed_baseline.astype(float) - 1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Bottom 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alpaca-7b_concise       4.463108\n",
       "phi-2                   4.395548\n",
       "baize-v2-7b             4.382565\n",
       "chatglm2-6b             4.359283\n",
       "pythia-12b-mix-sft      4.221362\n",
       "falcon-7b-instruct      4.036938\n",
       "oasst-sft-pythia-12b    3.270102\n",
       "guanaco-13b             3.003787\n",
       "guanaco-7b              2.871117\n",
       "baichuan-13b-chat       2.062170\n",
       "Name: np.tanh(rand_delta_len_std_only) + instruction_difficulty + not_gamed_baseline.astype(float) - 1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(lb, formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd98db20-be40-4564-9523-f8d7aa8af876",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_metrics = report(lb, formula, is_return_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfc7dd-6986-4d2a-8732-e3b4e9a03e3a",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- gameability is low (lower than the two other metrics)\n",
    "- length correlation is similar to Arena (similar to length normalized)\n",
    "- human correlation is extremely high (even higher than length normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "113bc9c2-7587-4b36-8eb0-2f4370cc954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save weights\n",
    "# weights = pd.DataFrame({m: models[m].coef_[0] for m in models.keys()}).T\n",
    "# weights.columns = [\"np.tanh(rand_delta_len_std_only)\",\"instruction_difficulty\",\"not_gamed_baseline.astype(float)\"]\n",
    "# weights.to_csv(\"weight_controlled.csv\", float_format='%.16f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f590e5-873a-405c-96e6-b347d04c2af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a492d .row14 {\n",
       "  border-bottom: 1.5px solid black;\n",
       "}\n",
       "#T_a492d_row0_col3, #T_a492d_row17_col4 {\n",
       "  background-color: #a7d0e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row0_col4, #T_a492d_row1_col3, #T_a492d_row1_col4, #T_a492d_row19_col3 {\n",
       "  background-color: #f7f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row2_col3, #T_a492d_row12_col4 {\n",
       "  background-color: #e48066;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a492d_row2_col4 {\n",
       "  background-color: #f8bda1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row3_col3 {\n",
       "  background-color: #f8bfa4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row3_col4, #T_a492d_row5_col4 {\n",
       "  background-color: #fae9df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row4_col3 {\n",
       "  background-color: #f5a886;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row4_col4 {\n",
       "  background-color: #fcd7c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row5_col3 {\n",
       "  background-color: #facab1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row6_col3 {\n",
       "  background-color: #f6b394;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row6_col4 {\n",
       "  background-color: #fbd0b9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row7_col3 {\n",
       "  background-color: #fbceb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row7_col4, #T_a492d_row16_col4 {\n",
       "  background-color: #f9ede5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row8_col3 {\n",
       "  background-color: #f9c6ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row8_col4 {\n",
       "  background-color: #fbe3d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row9_col3 {\n",
       "  background-color: #f9c2a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row9_col4 {\n",
       "  background-color: #f9c4a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row10_col3 {\n",
       "  background-color: #fbe6da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row10_col4, #T_a492d_row19_col4 {\n",
       "  background-color: #edf2f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row11_col3 {\n",
       "  background-color: #fce0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row11_col4, #T_a492d_row15_col4 {\n",
       "  background-color: #f8f3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row12_col3 {\n",
       "  background-color: #f5aa89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row13_col3 {\n",
       "  background-color: #deebf2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row13_col4, #T_a492d_row14_col4 {\n",
       "  background-color: #bddbea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row14_col3 {\n",
       "  background-color: #e6eff4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row15_col3 {\n",
       "  background-color: #f9f0eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row16_col3 {\n",
       "  background-color: #f8f2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row17_col3 {\n",
       "  background-color: #f5f6f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row18_col3 {\n",
       "  background-color: #f6f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a492d_row18_col4 {\n",
       "  background-color: #d2e6f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a492d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a492d_level0_col0\" class=\"col_heading level0 col0\" >Length</th>\n",
       "      <th id=\"T_a492d_level0_col1\" class=\"col_heading level0 col1\" >Win Rate</th>\n",
       "      <th id=\"T_a492d_level0_col2\" class=\"col_heading level0 col2\" >New Win Rate</th>\n",
       "      <th id=\"T_a492d_level0_col3\" class=\"col_heading level0 col3\" >Win Rate Gain</th>\n",
       "      <th id=\"T_a492d_level0_col4\" class=\"col_heading level0 col4\" >Rank Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row0\" class=\"row_heading level0 row0\" >gpt4_1106_preview_verbose</th>\n",
       "      <td id=\"T_a492d_row0_col0\" class=\"data row0 col0\" >2402</td>\n",
       "      <td id=\"T_a492d_row0_col1\" class=\"data row0 col1\" >64.3</td>\n",
       "      <td id=\"T_a492d_row0_col2\" class=\"data row0 col2\" >51.6</td>\n",
       "      <td id=\"T_a492d_row0_col3\" class=\"data row0 col3\" >-12.7</td>\n",
       "      <td id=\"T_a492d_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row1\" class=\"row_heading level0 row1\" >gpt4_1106_preview</th>\n",
       "      <td id=\"T_a492d_row1_col0\" class=\"data row1 col0\" >2049</td>\n",
       "      <td id=\"T_a492d_row1_col1\" class=\"data row1 col1\" >50.0</td>\n",
       "      <td id=\"T_a492d_row1_col2\" class=\"data row1 col2\" >50.0</td>\n",
       "      <td id=\"T_a492d_row1_col3\" class=\"data row1 col3\" >0.0</td>\n",
       "      <td id=\"T_a492d_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row2\" class=\"row_heading level0 row2\" >gpt4_1106_preview_concise</th>\n",
       "      <td id=\"T_a492d_row2_col0\" class=\"data row2 col0\" >1136</td>\n",
       "      <td id=\"T_a492d_row2_col1\" class=\"data row2 col1\" >22.9</td>\n",
       "      <td id=\"T_a492d_row2_col2\" class=\"data row2 col2\" >41.9</td>\n",
       "      <td id=\"T_a492d_row2_col3\" class=\"data row2 col3\" >19.0</td>\n",
       "      <td id=\"T_a492d_row2_col4\" class=\"data row2 col4\" >13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row3\" class=\"row_heading level0 row3\" >claude-3-opus-20240229</th>\n",
       "      <td id=\"T_a492d_row3_col0\" class=\"data row3 col0\" >1388</td>\n",
       "      <td id=\"T_a492d_row3_col1\" class=\"data row3 col1\" >29.0</td>\n",
       "      <td id=\"T_a492d_row3_col2\" class=\"data row3 col2\" >40.4</td>\n",
       "      <td id=\"T_a492d_row3_col3\" class=\"data row3 col3\" >11.4</td>\n",
       "      <td id=\"T_a492d_row3_col4\" class=\"data row3 col4\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row4\" class=\"row_heading level0 row4\" >gpt4</th>\n",
       "      <td id=\"T_a492d_row4_col0\" class=\"data row4 col0\" >1365</td>\n",
       "      <td id=\"T_a492d_row4_col1\" class=\"data row4 col1\" >23.6</td>\n",
       "      <td id=\"T_a492d_row4_col2\" class=\"data row4 col2\" >38.1</td>\n",
       "      <td id=\"T_a492d_row4_col3\" class=\"data row4 col3\" >14.6</td>\n",
       "      <td id=\"T_a492d_row4_col4\" class=\"data row4 col4\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row5\" class=\"row_heading level0 row5\" >Qwen1.5-72B-Chat</th>\n",
       "      <td id=\"T_a492d_row5_col0\" class=\"data row5 col0\" >1549</td>\n",
       "      <td id=\"T_a492d_row5_col1\" class=\"data row5 col1\" >26.5</td>\n",
       "      <td id=\"T_a492d_row5_col2\" class=\"data row5 col2\" >36.6</td>\n",
       "      <td id=\"T_a492d_row5_col3\" class=\"data row5 col3\" >10.1</td>\n",
       "      <td id=\"T_a492d_row5_col4\" class=\"data row5 col4\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row6\" class=\"row_heading level0 row6\" >gpt4_0314</th>\n",
       "      <td id=\"T_a492d_row6_col0\" class=\"data row6 col0\" >1371</td>\n",
       "      <td id=\"T_a492d_row6_col1\" class=\"data row6 col1\" >22.1</td>\n",
       "      <td id=\"T_a492d_row6_col2\" class=\"data row6 col2\" >35.3</td>\n",
       "      <td id=\"T_a492d_row6_col3\" class=\"data row6 col3\" >13.2</td>\n",
       "      <td id=\"T_a492d_row6_col4\" class=\"data row6 col4\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row7\" class=\"row_heading level0 row7\" >claude-3-sonnet-20240229</th>\n",
       "      <td id=\"T_a492d_row7_col0\" class=\"data row7 col0\" >1420</td>\n",
       "      <td id=\"T_a492d_row7_col1\" class=\"data row7 col1\" >25.6</td>\n",
       "      <td id=\"T_a492d_row7_col2\" class=\"data row7 col2\" >34.9</td>\n",
       "      <td id=\"T_a492d_row7_col3\" class=\"data row7 col3\" >9.3</td>\n",
       "      <td id=\"T_a492d_row7_col4\" class=\"data row7 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row8\" class=\"row_heading level0 row8\" >gpt4_0613_verbose</th>\n",
       "      <td id=\"T_a492d_row8_col0\" class=\"data row8 col0\" >1473</td>\n",
       "      <td id=\"T_a492d_row8_col1\" class=\"data row8 col1\" >23.2</td>\n",
       "      <td id=\"T_a492d_row8_col2\" class=\"data row8 col2\" >33.8</td>\n",
       "      <td id=\"T_a492d_row8_col3\" class=\"data row8 col3\" >10.6</td>\n",
       "      <td id=\"T_a492d_row8_col4\" class=\"data row8 col4\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row9\" class=\"row_heading level0 row9\" >mistral-large-2402</th>\n",
       "      <td id=\"T_a492d_row9_col0\" class=\"data row9 col0\" >1362</td>\n",
       "      <td id=\"T_a492d_row9_col1\" class=\"data row9 col1\" >21.4</td>\n",
       "      <td id=\"T_a492d_row9_col2\" class=\"data row9 col2\" >32.7</td>\n",
       "      <td id=\"T_a492d_row9_col3\" class=\"data row9 col3\" >11.2</td>\n",
       "      <td id=\"T_a492d_row9_col4\" class=\"data row9 col4\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row10\" class=\"row_heading level0 row10\" >Samba-CoE-v0.2-best-of-16</th>\n",
       "      <td id=\"T_a492d_row10_col0\" class=\"data row10 col0\" >1578</td>\n",
       "      <td id=\"T_a492d_row10_col1\" class=\"data row10 col1\" >27.0</td>\n",
       "      <td id=\"T_a492d_row10_col2\" class=\"data row10 col2\" >31.5</td>\n",
       "      <td id=\"T_a492d_row10_col3\" class=\"data row10 col3\" >4.5</td>\n",
       "      <td id=\"T_a492d_row10_col4\" class=\"data row10 col4\" >-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row11\" class=\"row_heading level0 row11\" >claude-2.1_verbose</th>\n",
       "      <td id=\"T_a492d_row11_col0\" class=\"data row11 col0\" >1414</td>\n",
       "      <td id=\"T_a492d_row11_col1\" class=\"data row11 col1\" >24.4</td>\n",
       "      <td id=\"T_a492d_row11_col2\" class=\"data row11 col2\" >30.3</td>\n",
       "      <td id=\"T_a492d_row11_col3\" class=\"data row11 col3\" >5.9</td>\n",
       "      <td id=\"T_a492d_row11_col4\" class=\"data row11 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row12\" class=\"row_heading level0 row12\" >gpt4_0613</th>\n",
       "      <td id=\"T_a492d_row12_col0\" class=\"data row12 col0\" >1140</td>\n",
       "      <td id=\"T_a492d_row12_col1\" class=\"data row12 col1\" >15.8</td>\n",
       "      <td id=\"T_a492d_row12_col2\" class=\"data row12 col2\" >30.2</td>\n",
       "      <td id=\"T_a492d_row12_col3\" class=\"data row12 col3\" >14.4</td>\n",
       "      <td id=\"T_a492d_row12_col4\" class=\"data row12 col4\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row13\" class=\"row_heading level0 row13\" >Snorkel-Mistral-PairRM-DPO-best-of-16</th>\n",
       "      <td id=\"T_a492d_row13_col0\" class=\"data row13 col0\" >2616</td>\n",
       "      <td id=\"T_a492d_row13_col1\" class=\"data row13 col1\" >34.9</td>\n",
       "      <td id=\"T_a492d_row13_col2\" class=\"data row13 col2\" >30.0</td>\n",
       "      <td id=\"T_a492d_row13_col3\" class=\"data row13 col3\" >-4.9</td>\n",
       "      <td id=\"T_a492d_row13_col4\" class=\"data row13 col4\" >-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row14\" class=\"row_heading level0 row14\" >Contextual-KTO-Mistral-PairRM</th>\n",
       "      <td id=\"T_a492d_row14_col0\" class=\"data row14 col0\" >2521</td>\n",
       "      <td id=\"T_a492d_row14_col1\" class=\"data row14 col1\" >33.2</td>\n",
       "      <td id=\"T_a492d_row14_col2\" class=\"data row14 col2\" >29.7</td>\n",
       "      <td id=\"T_a492d_row14_col3\" class=\"data row14 col3\" >-3.5</td>\n",
       "      <td id=\"T_a492d_row14_col4\" class=\"data row14 col4\" >-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row15\" class=\"row_heading level0 row15\" >falcon-7b-instruct</th>\n",
       "      <td id=\"T_a492d_row15_col0\" class=\"data row15 col0\" >478</td>\n",
       "      <td id=\"T_a492d_row15_col1\" class=\"data row15 col1\" >2.1</td>\n",
       "      <td id=\"T_a492d_row15_col2\" class=\"data row15 col2\" >4.0</td>\n",
       "      <td id=\"T_a492d_row15_col3\" class=\"data row15 col3\" >1.9</td>\n",
       "      <td id=\"T_a492d_row15_col4\" class=\"data row15 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row16\" class=\"row_heading level0 row16\" >oasst-sft-pythia-12b</th>\n",
       "      <td id=\"T_a492d_row16_col0\" class=\"data row16 col0\" >726</td>\n",
       "      <td id=\"T_a492d_row16_col1\" class=\"data row16 col1\" >1.8</td>\n",
       "      <td id=\"T_a492d_row16_col2\" class=\"data row16 col2\" >3.3</td>\n",
       "      <td id=\"T_a492d_row16_col3\" class=\"data row16 col3\" >1.5</td>\n",
       "      <td id=\"T_a492d_row16_col4\" class=\"data row16 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row17\" class=\"row_heading level0 row17\" >guanaco-13b</th>\n",
       "      <td id=\"T_a492d_row17_col0\" class=\"data row17 col0\" >1774</td>\n",
       "      <td id=\"T_a492d_row17_col1\" class=\"data row17 col1\" >3.5</td>\n",
       "      <td id=\"T_a492d_row17_col2\" class=\"data row17 col2\" >3.0</td>\n",
       "      <td id=\"T_a492d_row17_col3\" class=\"data row17 col3\" >-0.5</td>\n",
       "      <td id=\"T_a492d_row17_col4\" class=\"data row17 col4\" >-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row18\" class=\"row_heading level0 row18\" >guanaco-7b</th>\n",
       "      <td id=\"T_a492d_row18_col0\" class=\"data row18 col0\" >1364</td>\n",
       "      <td id=\"T_a492d_row18_col1\" class=\"data row18 col1\" >2.9</td>\n",
       "      <td id=\"T_a492d_row18_col2\" class=\"data row18 col2\" >2.9</td>\n",
       "      <td id=\"T_a492d_row18_col3\" class=\"data row18 col3\" >-0.0</td>\n",
       "      <td id=\"T_a492d_row18_col4\" class=\"data row18 col4\" >-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a492d_level0_row19\" class=\"row_heading level0 row19\" >baichuan-13b-chat</th>\n",
       "      <td id=\"T_a492d_row19_col0\" class=\"data row19 col0\" >1727</td>\n",
       "      <td id=\"T_a492d_row19_col1\" class=\"data row19 col1\" >2.0</td>\n",
       "      <td id=\"T_a492d_row19_col2\" class=\"data row19 col2\" >2.1</td>\n",
       "      <td id=\"T_a492d_row19_col3\" class=\"data row19 col3\" >0.1</td>\n",
       "      <td id=\"T_a492d_row19_col4\" class=\"data row19 col4\" >-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b5c2d090>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting.show_new_lb(lb, \"np.tanh(rand_delta_len_std_only) + instruction_difficulty + not_gamed_baseline.astype(float) - 1\", n=15, n_tail=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd949cbd-bb95-4800-8f10-63095c095ea5",
   "metadata": {},
   "source": [
    "## Predicting win-rates and ELO scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc3b8c58-a686-47b2-a4dd-d9e6cc8089f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca_eval.metrics.glm_winrate import predict_winrate\n",
    "\n",
    "def predict_elo(p, scale=400, baseline_elo=dict_arena[BASELINE], **kwargs):    \n",
    "    return scale * np.log10(p/(1-p)) + baseline_elo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043133a-0b09-41ee-beb5-f0747fb5bb13",
   "metadata": {},
   "source": [
    "Let's compute the win rate between gemini and mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ba44847-8e03-486c-bb39-2148a7f2cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4972910406584219"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 'claude-2'\n",
    "m = 'mistral-medium'\n",
    "predict_winrate(n,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b5417-a499-4ccd-a64f-7087b402879d",
   "metadata": {},
   "source": [
    "We can also predict ELO scores very easily (note we could also do that before by comparing all to the same model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5482374-61a4-409d-9993-bac7c79a3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpacaElo = predict_elo(lb.query(\"mode != 'dev'\")[formula]/100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c67ad33-0f83-4ff9-be11-bd5a80afcb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpt4_1106_preview         1251.000000\n",
       "claude-3-opus-20240229    1183.394708\n",
       "gpt4                      1166.900609\n",
       "Qwen1.5-72B-Chat          1155.345236\n",
       "gpt4_0314                 1145.801875\n",
       "                             ...     \n",
       "falcon-7b-instruct         700.579174\n",
       "oasst-sft-pythia-12b       662.600234\n",
       "guanaco-13b                647.365762\n",
       "guanaco-7b                 639.280987\n",
       "baichuan-13b-chat          580.349617\n",
       "Name: np.tanh(rand_delta_len_std_only) + instruction_difficulty + not_gamed_baseline.astype(float) - 1, Length: 123, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpacaElo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3cc7204-d14c-4d40-828f-2c0ebc9c90a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.9517213180367523, pvalue=4.7446031921545354e-20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.pearsonr(lb_arena[\"ELO\"].values, alpacaElo.loc[lb_arena[\"ELO\"].index].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f677b25-6746-417d-b1c3-22322778c392",
   "metadata": {},
   "source": [
    "And so we see that Pearson correlation with the Arena ELO is >95%, so super high as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5baa5-5c29-46fd-972f-beb72c5f59bf",
   "metadata": {},
   "source": [
    "## More explanations about the GLM\n",
    "\n",
    "### Regularization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Recall:\n",
    "\n",
    "$$win\\_rate(m,b) = \\frac{1}{N} \\sum_{i=1}^{N} logistic(\\mathbf{w}'_l[m] * tanh(length(m(x_i)) - length(b(x_i))) + w'_{x}[m] * embedding(x_i)  + \\mathbf{w}'_m[m]) $$\n",
    "\n",
    "with $w'_{x}[m] = (w_{x}[m] - w_{x}[b])$ and $\\mathbf{w}'_m[m] = (\\mathbf{w}_m[m] - \\mathbf{w}_m[b])$ and $\\mathbf{w}'_l[m] = \\mathbf{w}_l[(m,b)]$.\n",
    "\n",
    "To avoid having having models that are too gameable, we actually regularize $\\mathbf{w'}_l[m]$ to be close to $\\mathbf{w'}_l[b]$.\n",
    "Do do so we use all the outputs from the baseline with different length (`verbose`, `concise`) and note that if we knew they were from the baseline, then all the weights should be the same as the baseline but the predictions would be different (it has a different prompt). We deote the modified baseline as $b'$. The let's call $\\mathcal{L}_i$ negative loglikelihood between predicted preference and the actual one. We would then be minimizing:\n",
    "\n",
    "$$min_{\\mathbf{w'}_l[b]} \\sum_i \\mathcal{L}_i(logistic( \\mathbf{w'}_l[b]  * tanh(standardized(length(b'(x_i)) - length(b(x_i))))$$\n",
    "\n",
    "we can then fit this equation and get $\\mathbf{w'}_l[b]$, and add that as a regularizer when fitting other models\n",
    "\n",
    "\n",
    "$$min_{\\mathbf{w'}_l[m], \\mathbf{w'}_{x}[m], \\mathbf{w'}_{m}[m]} \\sum_i  \\mathcal{L}_i(logistic( \\mathbf{w'}_l[m]  * tanh(standardized(length(m(x_i)) - length(b(x_i)))) + \\mathbf{w'}_x[m] * embedding(x_i)  + \\mathbf{w}'_m[m] ) + \\lambda |(\\mathbf{w'}_l[b] - \\mathbf{w'}_l[m])|$$\n",
    "\n",
    "The intuition of the regularizer is that you don't ever want the model to be explain to explain much more with length than it does for the verbose and concise version of the baseline. In other words, we use the parameter from the baseline as our prior for the value of that parameter.\n",
    "\n",
    "Regularizing a single parameter (and to a specific value) is not possible in fast optimization of logistic regressions, so we **instead optimize both objective simultaneously with tied parameters**\n",
    "\n",
    "$$min_{\\mathbf{w'}_l[m], \\mathbf{w'}_{x}[m], \\mathbf{w'}_{m}[m]} \\sum_i  \\mathcal{L}_i(logistic( \\mathbf{w'}_l[m]  * tanh(standardized(length(m(x_i)) - length(b(x_i)))) + \\mathbf{w'}_x[m] * embedding(x_i)  + \\mathbf{w}'_m[m] ) + \\lambda' \\mathcal{L}_i(logistic( \\mathbf{w'}_l[m]  * tanh(standardized(length(b'(x_i)) - length(b(x_i))))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e26e1-ae68-4cc4-b188-987f2de43263",
   "metadata": {},
   "source": [
    "# Other metrics to consider\n",
    "\n",
    "\n",
    "## Balanced win-rate\n",
    "\n",
    "Background: oen common way to control for a covariate that you don't want to take into account is by stratification. Here we will stratify the data by \"longer than baseline\" and \"shorter than baseline\".\n",
    "\n",
    "- **What**: compute the expected number of times that the model is better than the baseline when the outputs of the model are (1) longer, and (2) shorter than the baseline. Then take the average between both settings.\n",
    "- **Benefits**:\n",
    "    - **(D1,D2,D3) metrics**: much better in all metrics than raw win-rate, although seems to overcorrect length bias.\n",
    "    - **(D4) simplicity**: simple to understand\n",
    "    - **(D5) interpretability**: simple to interpret & similar interpretation as win-rate\n",
    "    - **(D8) independence**: can apply the correction independently of each model.\n",
    "- **Downside**:\n",
    "    - there might be a cofounder between the complexity of the task and which outputs are longer.\n",
    "    - **(D6) generality**: although the  procedure. Hard to apply for other biases, given that it would split the space exponentially.\n",
    "    - **(D7) robustness**: not robust for cases where there are very few answer that are either short or longer than the baseline.  High variance / gameable if models have only a few outputs in one of the two categories. E.g. everything is shorter than baseline => should not allow evla of such model.\n",
    "    - **(D2') adversarially gameable**: our adversarial attack works super well because you get weighted with 100% win rate. It becomes one of the best method.\n",
    " \n",
    "Overall I like this simple (to compute & to interpret) controlled-length. I think it's better in most respect than the raw win rate. My major worry is that it makes the metric really bad in the case of models that are nearly always shorter or longer than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "992e25da-c3d0-4fcd-ba56-07f2d2e3cc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Report for **balanced_win_rate**\n",
      "\n",
      "## Gameability (lower is better)\n",
      "Verbosity gameability (relative std metric): 12.2%\n",
      "Conciseness gameability (relative std metric): 18.6%\n",
      "Adversarial winrate gain: 40.8\n",
      "Adversarial rank gain: 114.0\n",
      "\n",
      "## Correlation with Arena (higher is better)\n",
      "Spearman Corr: 0.951\n",
      "Kendall Corr: 0.836\n",
      "\n",
      "## Correlation with length (closer to spearman=0.35, kendall=0.25 is better)\n",
      "Spearman Corr: 0.268\n",
      "Kendall Corr: 0.185\n",
      "\n",
      "## Top 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gpt4_1106_preview_verbose    55.464179\n",
       "gpt4_1106_preview                 50.0\n",
       "gpt4_gamed                   44.532377\n",
       "gpt4_1106_preview_concise    42.476316\n",
       "claude-3-opus-20240229       39.494379\n",
       "mistral-large-2402           37.141506\n",
       "Qwen1.5-72B-Chat             37.072419\n",
       "gpt4                         36.503486\n",
       "claude-3-sonnet-20240229     35.516836\n",
       "gpt4_0613_verbose            32.752569\n",
       "Name: balanced_win_rate, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Bottom 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alpaca-7b_concise       6.673438\n",
       "gemma-2b-it             6.002278\n",
       "baize-v2-7b             5.322234\n",
       "guanaco-7b              4.644985\n",
       "chatglm2-6b             4.570916\n",
       "guanaco-13b             4.103434\n",
       "pythia-12b-mix-sft      3.344637\n",
       "phi-2                   3.105325\n",
       "baichuan-13b-chat       2.464749\n",
       "oasst-sft-pythia-12b    2.274166\n",
       "Name: balanced_win_rate, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_metrics_for_longer_balancing(lb, all_df_annotations):\n",
    "    \"\"\"Computes the mean and variance fo win rate grouped by whether the model is longer/shorter than the baseline\"\"\"\n",
    "    lb = lb.copy()\n",
    "    keys = [\"mean_1longer\", \"mean_2longer\", \"var_1longer\", \"var_2longer\", \"count_2longer\", \"count_2longer\",\n",
    "           \n",
    "           ]\n",
    "    annotations = {}\n",
    "    for k in keys:\n",
    "        lb[k] = None\n",
    "        \n",
    "    for i in lb.index:\n",
    "        # load actual annotations to see if it was longer or not \n",
    "        df_annotations = all_df_annotations[all_df_annotations.model == i]\n",
    "\n",
    "        lb.loc[i,\"mean\"] = df_annotations[\"preference\"].mean()\n",
    "        groupby_islonger1 = df_annotations.groupby(\"is_longer1\")[\"preference\"].agg([\"mean\", \"var\"])\n",
    "        groupby_islonger2 = df_annotations.groupby(\"is_longer2\")[\"preference\"].agg([\"mean\", \"var\"])\n",
    "        is_same_length = df_annotations[\"is_same_length\"].sum()        \n",
    "\n",
    "        # uses islonger1/2 instead of true false to deal with same lengths\n",
    "        try:\n",
    "            lb.loc[i, \"mean_1longer\"] = groupby_islonger1.loc[True, \"mean\"]\n",
    "            lb.loc[i, \"mean_2longer\"] = groupby_islonger2.loc[True, \"mean\"]\n",
    "            lb.loc[i, \"var_1longer\"] = groupby_islonger1.loc[True, \"var\"]\n",
    "            lb.loc[i, \"var_2longer\"] = groupby_islonger2.loc[True, \"var\"]\n",
    "            \n",
    "        except: # case where all is shorter or longer or same\n",
    "            lb.loc[i, \"mean_1longer\"] = lb.loc[i, \"mean_2longer\"] = df_annotations[\"preference\"].mean()\n",
    "            lb.loc[i, \"var_1longer\"] = lb.loc[i, \"var_2longer\"] = df_annotations[\"preference\"].var()\n",
    "        \n",
    "        lb.loc[i, \"count_1longer\"] = df_annotations[\"is_longer1\"].sum() + is_same_length/2\n",
    "        lb.loc[i, \"count_2longer\"] = df_annotations[\"is_longer2\"].sum() + is_same_length/2\n",
    "            \n",
    "\n",
    "    return lb\n",
    "\n",
    "lb_longer = add_metrics_for_longer_balancing(lb, all_df_annotations)\n",
    "lb_longer[\"balanced_win_rate\"] = ((lb_longer[\"mean_1longer\"] + lb_longer[\"mean_2longer\"])/2)*100\n",
    "report(lb_longer, \"balanced_win_rate\", is_detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bde4cf7f-b626-42ec-a019-933026fba82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_metrics = report(lb_longer, \"balanced_win_rate\", is_detailed=False, is_return_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7485108-8060-4ae9-8f20-ce79a4082f66",
   "metadata": {},
   "source": [
    "We see that:\n",
    "- gameability reduced by ~1.5-2x\n",
    "- correlation with Arena increased slightly\n",
    "- correlation with length is very small.\n",
    "\n",
    "Overall, this seems like a net gain. Note that the correlation with the length leaderboard is much smaller than humans, suggesting that we might have overcorrected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3df6822f-6358-46b8-a6b0-fa44aba6c7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a999d .row14 {\n",
       "  border-bottom: 1.5px solid black;\n",
       "}\n",
       "#T_a999d_row0_col3 {\n",
       "  background-color: #cae1ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row0_col4, #T_a999d_row1_col3, #T_a999d_row1_col4, #T_a999d_row16_col4 {\n",
       "  background-color: #f7f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row2_col3, #T_a999d_row9_col4 {\n",
       "  background-color: #e48066;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a999d_row2_col4 {\n",
       "  background-color: #f5aa89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row3_col3, #T_a999d_row5_col3 {\n",
       "  background-color: #fac8af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row3_col4, #T_a999d_row5_col4, #T_a999d_row6_col4, #T_a999d_row10_col3 {\n",
       "  background-color: #fae9df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row4_col3 {\n",
       "  background-color: #f7b799;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row4_col4 {\n",
       "  background-color: #fddcc9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row6_col3 {\n",
       "  background-color: #fcd3bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row7_col3, #T_a999d_row15_col4 {\n",
       "  background-color: #fbccb4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row7_col4 {\n",
       "  background-color: #f9eee7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row8_col3 {\n",
       "  background-color: #fbceb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row8_col4, #T_a999d_row11_col3 {\n",
       "  background-color: #fce0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row9_col3 {\n",
       "  background-color: #f3a481;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row10_col4 {\n",
       "  background-color: #cce2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row11_col4 {\n",
       "  background-color: #e0ecf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row12_col3 {\n",
       "  background-color: #f6b191;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row12_col4 {\n",
       "  background-color: #f2a17f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row13_col3 {\n",
       "  background-color: #e7f0f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row13_col4, #T_a999d_row14_col4 {\n",
       "  background-color: #c2ddec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row14_col3 {\n",
       "  background-color: #edf2f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row15_col3 {\n",
       "  background-color: #fbe6da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row16_col3, #T_a999d_row19_col3 {\n",
       "  background-color: #f7f5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row17_col3 {\n",
       "  background-color: #f8f4f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row17_col4 {\n",
       "  background-color: #9bc9e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row18_col3 {\n",
       "  background-color: #f8f1ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row18_col4 {\n",
       "  background-color: #e6eff4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a999d_row19_col4 {\n",
       "  background-color: #f2f5f6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a999d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a999d_level0_col0\" class=\"col_heading level0 col0\" >Length</th>\n",
       "      <th id=\"T_a999d_level0_col1\" class=\"col_heading level0 col1\" >Win Rate</th>\n",
       "      <th id=\"T_a999d_level0_col2\" class=\"col_heading level0 col2\" >New Win Rate</th>\n",
       "      <th id=\"T_a999d_level0_col3\" class=\"col_heading level0 col3\" >Win Rate Gain</th>\n",
       "      <th id=\"T_a999d_level0_col4\" class=\"col_heading level0 col4\" >Rank Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row0\" class=\"row_heading level0 row0\" >gpt4_1106_preview_verbose</th>\n",
       "      <td id=\"T_a999d_row0_col0\" class=\"data row0 col0\" >2402</td>\n",
       "      <td id=\"T_a999d_row0_col1\" class=\"data row0 col1\" >64.3</td>\n",
       "      <td id=\"T_a999d_row0_col2\" class=\"data row0 col2\" >55.464179</td>\n",
       "      <td id=\"T_a999d_row0_col3\" class=\"data row0 col3\" >-8.839422</td>\n",
       "      <td id=\"T_a999d_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row1\" class=\"row_heading level0 row1\" >gpt4_1106_preview</th>\n",
       "      <td id=\"T_a999d_row1_col0\" class=\"data row1 col0\" >2049</td>\n",
       "      <td id=\"T_a999d_row1_col1\" class=\"data row1 col1\" >50.0</td>\n",
       "      <td id=\"T_a999d_row1_col2\" class=\"data row1 col2\" >50.000000</td>\n",
       "      <td id=\"T_a999d_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_a999d_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row2\" class=\"row_heading level0 row2\" >gpt4_1106_preview_concise</th>\n",
       "      <td id=\"T_a999d_row2_col0\" class=\"data row2 col0\" >1136</td>\n",
       "      <td id=\"T_a999d_row2_col1\" class=\"data row2 col1\" >22.9</td>\n",
       "      <td id=\"T_a999d_row2_col2\" class=\"data row2 col2\" >42.476316</td>\n",
       "      <td id=\"T_a999d_row2_col3\" class=\"data row2 col3\" >19.556121</td>\n",
       "      <td id=\"T_a999d_row2_col4\" class=\"data row2 col4\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row3\" class=\"row_heading level0 row3\" >claude-3-opus-20240229</th>\n",
       "      <td id=\"T_a999d_row3_col0\" class=\"data row3 col0\" >1388</td>\n",
       "      <td id=\"T_a999d_row3_col1\" class=\"data row3 col1\" >29.0</td>\n",
       "      <td id=\"T_a999d_row3_col2\" class=\"data row3 col2\" >39.494379</td>\n",
       "      <td id=\"T_a999d_row3_col3\" class=\"data row3 col3\" >10.452615</td>\n",
       "      <td id=\"T_a999d_row3_col4\" class=\"data row3 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row4\" class=\"row_heading level0 row4\" >gpt4</th>\n",
       "      <td id=\"T_a999d_row4_col0\" class=\"data row4 col0\" >1365</td>\n",
       "      <td id=\"T_a999d_row4_col1\" class=\"data row4 col1\" >23.6</td>\n",
       "      <td id=\"T_a999d_row4_col2\" class=\"data row4 col2\" >36.503486</td>\n",
       "      <td id=\"T_a999d_row4_col3\" class=\"data row4 col3\" >12.926697</td>\n",
       "      <td id=\"T_a999d_row4_col4\" class=\"data row4 col4\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row5\" class=\"row_heading level0 row5\" >Qwen1.5-72B-Chat</th>\n",
       "      <td id=\"T_a999d_row5_col0\" class=\"data row5 col0\" >1549</td>\n",
       "      <td id=\"T_a999d_row5_col1\" class=\"data row5 col1\" >26.5</td>\n",
       "      <td id=\"T_a999d_row5_col2\" class=\"data row5 col2\" >37.072419</td>\n",
       "      <td id=\"T_a999d_row5_col3\" class=\"data row5 col3\" >10.574135</td>\n",
       "      <td id=\"T_a999d_row5_col4\" class=\"data row5 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row6\" class=\"row_heading level0 row6\" >gpt4_0314</th>\n",
       "      <td id=\"T_a999d_row6_col0\" class=\"data row6 col0\" >1371</td>\n",
       "      <td id=\"T_a999d_row6_col1\" class=\"data row6 col1\" >22.1</td>\n",
       "      <td id=\"T_a999d_row6_col2\" class=\"data row6 col2\" >30.972772</td>\n",
       "      <td id=\"T_a999d_row6_col3\" class=\"data row6 col3\" >8.899513</td>\n",
       "      <td id=\"T_a999d_row6_col4\" class=\"data row6 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row7\" class=\"row_heading level0 row7\" >claude-3-sonnet-20240229</th>\n",
       "      <td id=\"T_a999d_row7_col0\" class=\"data row7 col0\" >1420</td>\n",
       "      <td id=\"T_a999d_row7_col1\" class=\"data row7 col1\" >25.6</td>\n",
       "      <td id=\"T_a999d_row7_col2\" class=\"data row7 col2\" >35.516836</td>\n",
       "      <td id=\"T_a999d_row7_col3\" class=\"data row7 col3\" >9.960510</td>\n",
       "      <td id=\"T_a999d_row7_col4\" class=\"data row7 col4\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row8\" class=\"row_heading level0 row8\" >gpt4_0613_verbose</th>\n",
       "      <td id=\"T_a999d_row8_col0\" class=\"data row8 col0\" >1473</td>\n",
       "      <td id=\"T_a999d_row8_col1\" class=\"data row8 col1\" >23.2</td>\n",
       "      <td id=\"T_a999d_row8_col2\" class=\"data row8 col2\" >32.752569</td>\n",
       "      <td id=\"T_a999d_row8_col3\" class=\"data row8 col3\" >9.515209</td>\n",
       "      <td id=\"T_a999d_row8_col4\" class=\"data row8 col4\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row9\" class=\"row_heading level0 row9\" >mistral-large-2402</th>\n",
       "      <td id=\"T_a999d_row9_col0\" class=\"data row9 col0\" >1362</td>\n",
       "      <td id=\"T_a999d_row9_col1\" class=\"data row9 col1\" >21.4</td>\n",
       "      <td id=\"T_a999d_row9_col2\" class=\"data row9 col2\" >37.141506</td>\n",
       "      <td id=\"T_a999d_row9_col3\" class=\"data row9 col3\" >15.702730</td>\n",
       "      <td id=\"T_a999d_row9_col4\" class=\"data row9 col4\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row10\" class=\"row_heading level0 row10\" >Samba-CoE-v0.2-best-of-16</th>\n",
       "      <td id=\"T_a999d_row10_col0\" class=\"data row10 col0\" >1578</td>\n",
       "      <td id=\"T_a999d_row10_col1\" class=\"data row10 col1\" >27.0</td>\n",
       "      <td id=\"T_a999d_row10_col2\" class=\"data row10 col2\" >30.778419</td>\n",
       "      <td id=\"T_a999d_row10_col3\" class=\"data row10 col3\" >3.790164</td>\n",
       "      <td id=\"T_a999d_row10_col4\" class=\"data row10 col4\" >-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row11\" class=\"row_heading level0 row11\" >claude-2.1_verbose</th>\n",
       "      <td id=\"T_a999d_row11_col0\" class=\"data row11 col0\" >1414</td>\n",
       "      <td id=\"T_a999d_row11_col1\" class=\"data row11 col1\" >24.4</td>\n",
       "      <td id=\"T_a999d_row11_col2\" class=\"data row11 col2\" >30.614862</td>\n",
       "      <td id=\"T_a999d_row11_col3\" class=\"data row11 col3\" >6.260791</td>\n",
       "      <td id=\"T_a999d_row11_col4\" class=\"data row11 col4\" >-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row12\" class=\"row_heading level0 row12\" >gpt4_0613</th>\n",
       "      <td id=\"T_a999d_row12_col0\" class=\"data row12 col0\" >1140</td>\n",
       "      <td id=\"T_a999d_row12_col1\" class=\"data row12 col1\" >15.8</td>\n",
       "      <td id=\"T_a999d_row12_col2\" class=\"data row12 col2\" >29.528662</td>\n",
       "      <td id=\"T_a999d_row12_col3\" class=\"data row12 col3\" >13.773624</td>\n",
       "      <td id=\"T_a999d_row12_col4\" class=\"data row12 col4\" >13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row13\" class=\"row_heading level0 row13\" >Snorkel-Mistral-PairRM-DPO-best-of-16</th>\n",
       "      <td id=\"T_a999d_row13_col0\" class=\"data row13 col0\" >2616</td>\n",
       "      <td id=\"T_a999d_row13_col1\" class=\"data row13 col1\" >34.9</td>\n",
       "      <td id=\"T_a999d_row13_col2\" class=\"data row13 col2\" >31.504510</td>\n",
       "      <td id=\"T_a999d_row13_col3\" class=\"data row13 col3\" >-3.355623</td>\n",
       "      <td id=\"T_a999d_row13_col4\" class=\"data row13 col4\" >-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row14\" class=\"row_heading level0 row14\" >Contextual-KTO-Mistral-PairRM</th>\n",
       "      <td id=\"T_a999d_row14_col0\" class=\"data row14 col0\" >2521</td>\n",
       "      <td id=\"T_a999d_row14_col1\" class=\"data row14 col1\" >33.2</td>\n",
       "      <td id=\"T_a999d_row14_col2\" class=\"data row14 col2\" >31.198200</td>\n",
       "      <td id=\"T_a999d_row14_col3\" class=\"data row14 col3\" >-2.029155</td>\n",
       "      <td id=\"T_a999d_row14_col4\" class=\"data row14 col4\" >-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row15\" class=\"row_heading level0 row15\" >falcon-7b-instruct</th>\n",
       "      <td id=\"T_a999d_row15_col0\" class=\"data row15 col0\" >478</td>\n",
       "      <td id=\"T_a999d_row15_col1\" class=\"data row15 col1\" >2.1</td>\n",
       "      <td id=\"T_a999d_row15_col2\" class=\"data row15 col2\" >6.787961</td>\n",
       "      <td id=\"T_a999d_row15_col3\" class=\"data row15 col3\" >4.641344</td>\n",
       "      <td id=\"T_a999d_row15_col4\" class=\"data row15 col4\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row16\" class=\"row_heading level0 row16\" >oasst-sft-pythia-12b</th>\n",
       "      <td id=\"T_a999d_row16_col0\" class=\"data row16 col0\" >726</td>\n",
       "      <td id=\"T_a999d_row16_col1\" class=\"data row16 col1\" >1.8</td>\n",
       "      <td id=\"T_a999d_row16_col2\" class=\"data row16 col2\" >2.274166</td>\n",
       "      <td id=\"T_a999d_row16_col3\" class=\"data row16 col3\" >0.484052</td>\n",
       "      <td id=\"T_a999d_row16_col4\" class=\"data row16 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row17\" class=\"row_heading level0 row17\" >guanaco-13b</th>\n",
       "      <td id=\"T_a999d_row17_col0\" class=\"data row17 col0\" >1774</td>\n",
       "      <td id=\"T_a999d_row17_col1\" class=\"data row17 col1\" >3.5</td>\n",
       "      <td id=\"T_a999d_row17_col2\" class=\"data row17 col2\" >4.103434</td>\n",
       "      <td id=\"T_a999d_row17_col3\" class=\"data row17 col3\" >0.633838</td>\n",
       "      <td id=\"T_a999d_row17_col4\" class=\"data row17 col4\" >-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row18\" class=\"row_heading level0 row18\" >guanaco-7b</th>\n",
       "      <td id=\"T_a999d_row18_col0\" class=\"data row18 col0\" >1364</td>\n",
       "      <td id=\"T_a999d_row18_col1\" class=\"data row18 col1\" >2.9</td>\n",
       "      <td id=\"T_a999d_row18_col2\" class=\"data row18 col2\" >4.644985</td>\n",
       "      <td id=\"T_a999d_row18_col3\" class=\"data row18 col3\" >1.764983</td>\n",
       "      <td id=\"T_a999d_row18_col4\" class=\"data row18 col4\" >-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a999d_level0_row19\" class=\"row_heading level0 row19\" >baichuan-13b-chat</th>\n",
       "      <td id=\"T_a999d_row19_col0\" class=\"data row19 col0\" >1727</td>\n",
       "      <td id=\"T_a999d_row19_col1\" class=\"data row19 col1\" >2.0</td>\n",
       "      <td id=\"T_a999d_row19_col2\" class=\"data row19 col2\" >2.464749</td>\n",
       "      <td id=\"T_a999d_row19_col3\" class=\"data row19 col3\" >0.472603</td>\n",
       "      <td id=\"T_a999d_row19_col4\" class=\"data row19 col4\" >-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b6510610>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting.show_new_lb(lb_longer, \"balanced_win_rate\", n=15, n_tail=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d33b8-af2e-4dc8-bb07-cc8117c958a8",
   "metadata": {},
   "source": [
    "## Length-normalized win-rate\n",
    "\n",
    "- **What**: Normalize the win-rate the bounded difference between the average baseline length and the average of the current model. To bound that difference, we squash it through a logistic function with a temperature that we hyperparameter tuned. Note taht we rescale everything so that the baseline stays at 50%. Also note that we could also rescale on a per sample basis rather than on the average. Both give similar results.\n",
    "- **Benefits**:\n",
    "    - **(D1-D3) metrics**: much better in all metrics than raw win-rate. **Metrics are better than balanced win-rate**. Note that it's harder to adversarially game because the correction is multiplicative => if you were bad it's hard to make it amazing. \n",
    "    - **(D4) simplicity**: simple to understand\n",
    "    - **(D8) independence**: can apply the correction independently of each model.\n",
    "- **Downside**:\n",
    "    - there might be a cofounder between the complexity of the task and which outputs are longer.\n",
    "    - **(D5) interpretability**: pretty hard to interpret, especially given that the mdoels are actually not compared on the same scale anymore (the unit is different), as not all models can achieve a win rate [0,100]. The range depends on the length of outputs. \n",
    "    - **(D6) generality**: not general\n",
    "    - **(D7) robustness**: Clearly wrong in the limits of long / short lengths. Really not robust because unclear functional form: will this hold for future models? will the temperature generalize? given that it was choosen emperically but across all models, it's unclear if there's something deep about the current functional form. \n",
    " \n",
    "Overall I'm honestly surprised at how good this metric performs. My main concerns are (1) that the functional form is clearly chosen on the current models and there's little reason to believe that it will generalize, and (2) the lack of interpretability given that the scaleof the metric is now length dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25eb7dd6-4d01-4c57-b6f4-959fe3b90b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Report for **avg_sigmoid_length_corrected_win_rate**\n",
      "\n",
      "## Gameability (lower is better)\n",
      "Verbosity gameability (relative std metric): 13.0%\n",
      "Conciseness gameability (relative std metric): 16.3%\n",
      "Adversarial winrate gain: 3.6\n",
      "Adversarial rank gain: 1.0\n",
      "\n",
      "## Correlation with Arena (higher is better)\n",
      "Spearman Corr: 0.964\n",
      "Kendall Corr: 0.853\n",
      "\n",
      "## Correlation with length (closer to spearman=0.35, kendall=0.25 is better)\n",
      "Spearman Corr: 0.343\n",
      "Kendall Corr: 0.233\n",
      "\n",
      "## Top 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gpt4_1106_preview            50.000000\n",
       "claude-3-opus-20240229       45.857774\n",
       "gpt4_1106_preview_verbose    42.502532\n",
       "claude-3-sonnet-20240229     39.800482\n",
       "gpt4_1106_preview_concise    39.481617\n",
       "Samba-CoE-v0.2-best-of-16    38.836285\n",
       "Qwen1.5-72B-Chat             38.743595\n",
       "claude-2.1_verbose           38.028529\n",
       "gpt4                         37.584082\n",
       "gpt4_0613_verbose            35.315026\n",
       "Name: avg_sigmoid_length_corrected_win_rate, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Bottom 10 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alpaca-7b               4.999603\n",
       "chatglm2-6b             4.890945\n",
       "pythia-12b-mix-sft      4.674240\n",
       "guanaco-7b              4.592913\n",
       "phi-2                   4.442420\n",
       "guanaco-13b             4.400390\n",
       "falcon-7b-instruct      4.115462\n",
       "alpaca-7b_concise       3.853242\n",
       "oasst-sft-pythia-12b    3.343088\n",
       "baichuan-13b-chat       2.612329\n",
       "Name: avg_sigmoid_length_corrected_win_rate, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(-np.logaddexp(0, -x))\n",
    "\n",
    "temperature=500\n",
    "lb[\"avg_sigmoid_length_corrected_win_rate\"] = lb[\"win_rate\"] * sigmoid((lb.loc[BASELINE, \"avg_length\"] - lb[\"avg_length\"] ) / temperature) * 2\n",
    "report(lb, \"avg_sigmoid_length_corrected_win_rate\", is_detailed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d857ac3b-5f72-41ec-bb52-44dc243d5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_metrics = report(lb, \"avg_sigmoid_length_corrected_win_rate\", is_detailed=False, is_return_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff021b62-0fa4-41a4-8c04-bb92e209718d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We see that:\n",
    "- gameability is low (similar to balanced win-rate)\n",
    "- length correlation is similar to Arena (better than balanced win-rate)\n",
    "- human correlation is extremely high (better than balanced win-rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7869acd4-bf9c-4b5b-aa7b-8c887b7a4f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5018a .row14 {\n",
       "  border-bottom: 1.5px solid black;\n",
       "}\n",
       "#T_5018a_row0_col3, #T_5018a_row13_col4 {\n",
       "  background-color: #6bacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5018a_row0_col4, #T_5018a_row19_col4 {\n",
       "  background-color: #f3f5f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row1_col3, #T_5018a_row15_col4 {\n",
       "  background-color: #f7f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row1_col4, #T_5018a_row16_col4, #T_5018a_row19_col3 {\n",
       "  background-color: #f7f5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row2_col3 {\n",
       "  background-color: #f5aa89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row2_col4 {\n",
       "  background-color: #fae8de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row3_col3 {\n",
       "  background-color: #f5a886;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row3_col4, #T_5018a_row6_col4 {\n",
       "  background-color: #f9efe9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row4_col3, #T_5018a_row7_col3 {\n",
       "  background-color: #f7b99c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row4_col4, #T_5018a_row8_col4, #T_5018a_row11_col4 {\n",
       "  background-color: #f9f0eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row5_col3, #T_5018a_row8_col3 {\n",
       "  background-color: #f9c6ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row5_col4, #T_5018a_row10_col4 {\n",
       "  background-color: #f8f3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row6_col3 {\n",
       "  background-color: #f8bfa4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row7_col4 {\n",
       "  background-color: #f9eee7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row9_col3 {\n",
       "  background-color: #f9c2a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row9_col4, #T_5018a_row12_col4 {\n",
       "  background-color: #fae9df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row10_col3 {\n",
       "  background-color: #fac8af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row11_col3 {\n",
       "  background-color: #f8bb9e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row12_col3 {\n",
       "  background-color: #facab1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row13_col3 {\n",
       "  background-color: #8dc2dc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row14_col3 {\n",
       "  background-color: #a7d0e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row14_col4 {\n",
       "  background-color: #93c6de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row15_col3, #T_5018a_row18_col3 {\n",
       "  background-color: #f8f1ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row16_col3 {\n",
       "  background-color: #f8f2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row17_col3 {\n",
       "  background-color: #f8f4f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row17_col4 {\n",
       "  background-color: #e1edf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5018a_row18_col4 {\n",
       "  background-color: #f2f5f6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5018a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5018a_level0_col0\" class=\"col_heading level0 col0\" >Length</th>\n",
       "      <th id=\"T_5018a_level0_col1\" class=\"col_heading level0 col1\" >Win Rate</th>\n",
       "      <th id=\"T_5018a_level0_col2\" class=\"col_heading level0 col2\" >New Win Rate</th>\n",
       "      <th id=\"T_5018a_level0_col3\" class=\"col_heading level0 col3\" >Win Rate Gain</th>\n",
       "      <th id=\"T_5018a_level0_col4\" class=\"col_heading level0 col4\" >Rank Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row0\" class=\"row_heading level0 row0\" >gpt4_1106_preview_verbose</th>\n",
       "      <td id=\"T_5018a_row0_col0\" class=\"data row0 col0\" >2402</td>\n",
       "      <td id=\"T_5018a_row0_col1\" class=\"data row0 col1\" >64.3</td>\n",
       "      <td id=\"T_5018a_row0_col2\" class=\"data row0 col2\" >42.5</td>\n",
       "      <td id=\"T_5018a_row0_col3\" class=\"data row0 col3\" >-21.8</td>\n",
       "      <td id=\"T_5018a_row0_col4\" class=\"data row0 col4\" >-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row1\" class=\"row_heading level0 row1\" >gpt4_1106_preview</th>\n",
       "      <td id=\"T_5018a_row1_col0\" class=\"data row1 col0\" >2049</td>\n",
       "      <td id=\"T_5018a_row1_col1\" class=\"data row1 col1\" >50.0</td>\n",
       "      <td id=\"T_5018a_row1_col2\" class=\"data row1 col2\" >50.0</td>\n",
       "      <td id=\"T_5018a_row1_col3\" class=\"data row1 col3\" >0.0</td>\n",
       "      <td id=\"T_5018a_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row2\" class=\"row_heading level0 row2\" >gpt4_1106_preview_concise</th>\n",
       "      <td id=\"T_5018a_row2_col0\" class=\"data row2 col0\" >1136</td>\n",
       "      <td id=\"T_5018a_row2_col1\" class=\"data row2 col1\" >22.9</td>\n",
       "      <td id=\"T_5018a_row2_col2\" class=\"data row2 col2\" >39.5</td>\n",
       "      <td id=\"T_5018a_row2_col3\" class=\"data row2 col3\" >16.6</td>\n",
       "      <td id=\"T_5018a_row2_col4\" class=\"data row2 col4\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row3\" class=\"row_heading level0 row3\" >claude-3-opus-20240229</th>\n",
       "      <td id=\"T_5018a_row3_col0\" class=\"data row3 col0\" >1388</td>\n",
       "      <td id=\"T_5018a_row3_col1\" class=\"data row3 col1\" >29.0</td>\n",
       "      <td id=\"T_5018a_row3_col2\" class=\"data row3 col2\" >45.9</td>\n",
       "      <td id=\"T_5018a_row3_col3\" class=\"data row3 col3\" >16.8</td>\n",
       "      <td id=\"T_5018a_row3_col4\" class=\"data row3 col4\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row4\" class=\"row_heading level0 row4\" >gpt4</th>\n",
       "      <td id=\"T_5018a_row4_col0\" class=\"data row4 col0\" >1365</td>\n",
       "      <td id=\"T_5018a_row4_col1\" class=\"data row4 col1\" >23.6</td>\n",
       "      <td id=\"T_5018a_row4_col2\" class=\"data row4 col2\" >37.6</td>\n",
       "      <td id=\"T_5018a_row4_col3\" class=\"data row4 col3\" >14.0</td>\n",
       "      <td id=\"T_5018a_row4_col4\" class=\"data row4 col4\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row5\" class=\"row_heading level0 row5\" >Qwen1.5-72B-Chat</th>\n",
       "      <td id=\"T_5018a_row5_col0\" class=\"data row5 col0\" >1549</td>\n",
       "      <td id=\"T_5018a_row5_col1\" class=\"data row5 col1\" >26.5</td>\n",
       "      <td id=\"T_5018a_row5_col2\" class=\"data row5 col2\" >38.7</td>\n",
       "      <td id=\"T_5018a_row5_col3\" class=\"data row5 col3\" >12.2</td>\n",
       "      <td id=\"T_5018a_row5_col4\" class=\"data row5 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row6\" class=\"row_heading level0 row6\" >gpt4_0314</th>\n",
       "      <td id=\"T_5018a_row6_col0\" class=\"data row6 col0\" >1371</td>\n",
       "      <td id=\"T_5018a_row6_col1\" class=\"data row6 col1\" >22.1</td>\n",
       "      <td id=\"T_5018a_row6_col2\" class=\"data row6 col2\" >35.1</td>\n",
       "      <td id=\"T_5018a_row6_col3\" class=\"data row6 col3\" >13.0</td>\n",
       "      <td id=\"T_5018a_row6_col4\" class=\"data row6 col4\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row7\" class=\"row_heading level0 row7\" >claude-3-sonnet-20240229</th>\n",
       "      <td id=\"T_5018a_row7_col0\" class=\"data row7 col0\" >1420</td>\n",
       "      <td id=\"T_5018a_row7_col1\" class=\"data row7 col1\" >25.6</td>\n",
       "      <td id=\"T_5018a_row7_col2\" class=\"data row7 col2\" >39.8</td>\n",
       "      <td id=\"T_5018a_row7_col3\" class=\"data row7 col3\" >14.2</td>\n",
       "      <td id=\"T_5018a_row7_col4\" class=\"data row7 col4\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row8\" class=\"row_heading level0 row8\" >gpt4_0613_verbose</th>\n",
       "      <td id=\"T_5018a_row8_col0\" class=\"data row8 col0\" >1473</td>\n",
       "      <td id=\"T_5018a_row8_col1\" class=\"data row8 col1\" >23.2</td>\n",
       "      <td id=\"T_5018a_row8_col2\" class=\"data row8 col2\" >35.3</td>\n",
       "      <td id=\"T_5018a_row8_col3\" class=\"data row8 col3\" >12.1</td>\n",
       "      <td id=\"T_5018a_row8_col4\" class=\"data row8 col4\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row9\" class=\"row_heading level0 row9\" >mistral-large-2402</th>\n",
       "      <td id=\"T_5018a_row9_col0\" class=\"data row9 col0\" >1362</td>\n",
       "      <td id=\"T_5018a_row9_col1\" class=\"data row9 col1\" >21.4</td>\n",
       "      <td id=\"T_5018a_row9_col2\" class=\"data row9 col2\" >34.2</td>\n",
       "      <td id=\"T_5018a_row9_col3\" class=\"data row9 col3\" >12.8</td>\n",
       "      <td id=\"T_5018a_row9_col4\" class=\"data row9 col4\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row10\" class=\"row_heading level0 row10\" >Samba-CoE-v0.2-best-of-16</th>\n",
       "      <td id=\"T_5018a_row10_col0\" class=\"data row10 col0\" >1578</td>\n",
       "      <td id=\"T_5018a_row10_col1\" class=\"data row10 col1\" >27.0</td>\n",
       "      <td id=\"T_5018a_row10_col2\" class=\"data row10 col2\" >38.8</td>\n",
       "      <td id=\"T_5018a_row10_col3\" class=\"data row10 col3\" >11.8</td>\n",
       "      <td id=\"T_5018a_row10_col4\" class=\"data row10 col4\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row11\" class=\"row_heading level0 row11\" >claude-2.1_verbose</th>\n",
       "      <td id=\"T_5018a_row11_col0\" class=\"data row11 col0\" >1414</td>\n",
       "      <td id=\"T_5018a_row11_col1\" class=\"data row11 col1\" >24.4</td>\n",
       "      <td id=\"T_5018a_row11_col2\" class=\"data row11 col2\" >38.0</td>\n",
       "      <td id=\"T_5018a_row11_col3\" class=\"data row11 col3\" >13.7</td>\n",
       "      <td id=\"T_5018a_row11_col4\" class=\"data row11 col4\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row12\" class=\"row_heading level0 row12\" >gpt4_0613</th>\n",
       "      <td id=\"T_5018a_row12_col0\" class=\"data row12 col0\" >1140</td>\n",
       "      <td id=\"T_5018a_row12_col1\" class=\"data row12 col1\" >15.8</td>\n",
       "      <td id=\"T_5018a_row12_col2\" class=\"data row12 col2\" >27.1</td>\n",
       "      <td id=\"T_5018a_row12_col3\" class=\"data row12 col3\" >11.4</td>\n",
       "      <td id=\"T_5018a_row12_col4\" class=\"data row12 col4\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row13\" class=\"row_heading level0 row13\" >Snorkel-Mistral-PairRM-DPO-best-of-16</th>\n",
       "      <td id=\"T_5018a_row13_col0\" class=\"data row13 col0\" >2616</td>\n",
       "      <td id=\"T_5018a_row13_col1\" class=\"data row13 col1\" >34.9</td>\n",
       "      <td id=\"T_5018a_row13_col2\" class=\"data row13 col2\" >17.0</td>\n",
       "      <td id=\"T_5018a_row13_col3\" class=\"data row13 col3\" >-17.9</td>\n",
       "      <td id=\"T_5018a_row13_col4\" class=\"data row13 col4\" >-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row14\" class=\"row_heading level0 row14\" >Contextual-KTO-Mistral-PairRM</th>\n",
       "      <td id=\"T_5018a_row14_col0\" class=\"data row14 col0\" >2521</td>\n",
       "      <td id=\"T_5018a_row14_col1\" class=\"data row14 col1\" >33.2</td>\n",
       "      <td id=\"T_5018a_row14_col2\" class=\"data row14 col2\" >18.6</td>\n",
       "      <td id=\"T_5018a_row14_col3\" class=\"data row14 col3\" >-14.6</td>\n",
       "      <td id=\"T_5018a_row14_col4\" class=\"data row14 col4\" >-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row15\" class=\"row_heading level0 row15\" >falcon-7b-instruct</th>\n",
       "      <td id=\"T_5018a_row15_col0\" class=\"data row15 col0\" >478</td>\n",
       "      <td id=\"T_5018a_row15_col1\" class=\"data row15 col1\" >2.1</td>\n",
       "      <td id=\"T_5018a_row15_col2\" class=\"data row15 col2\" >4.1</td>\n",
       "      <td id=\"T_5018a_row15_col3\" class=\"data row15 col3\" >2.0</td>\n",
       "      <td id=\"T_5018a_row15_col4\" class=\"data row15 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row16\" class=\"row_heading level0 row16\" >oasst-sft-pythia-12b</th>\n",
       "      <td id=\"T_5018a_row16_col0\" class=\"data row16 col0\" >726</td>\n",
       "      <td id=\"T_5018a_row16_col1\" class=\"data row16 col1\" >1.8</td>\n",
       "      <td id=\"T_5018a_row16_col2\" class=\"data row16 col2\" >3.3</td>\n",
       "      <td id=\"T_5018a_row16_col3\" class=\"data row16 col3\" >1.6</td>\n",
       "      <td id=\"T_5018a_row16_col4\" class=\"data row16 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row17\" class=\"row_heading level0 row17\" >guanaco-13b</th>\n",
       "      <td id=\"T_5018a_row17_col0\" class=\"data row17 col0\" >1774</td>\n",
       "      <td id=\"T_5018a_row17_col1\" class=\"data row17 col1\" >3.5</td>\n",
       "      <td id=\"T_5018a_row17_col2\" class=\"data row17 col2\" >4.4</td>\n",
       "      <td id=\"T_5018a_row17_col3\" class=\"data row17 col3\" >0.9</td>\n",
       "      <td id=\"T_5018a_row17_col4\" class=\"data row17 col4\" >-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row18\" class=\"row_heading level0 row18\" >guanaco-7b</th>\n",
       "      <td id=\"T_5018a_row18_col0\" class=\"data row18 col0\" >1364</td>\n",
       "      <td id=\"T_5018a_row18_col1\" class=\"data row18 col1\" >2.9</td>\n",
       "      <td id=\"T_5018a_row18_col2\" class=\"data row18 col2\" >4.6</td>\n",
       "      <td id=\"T_5018a_row18_col3\" class=\"data row18 col3\" >1.7</td>\n",
       "      <td id=\"T_5018a_row18_col4\" class=\"data row18 col4\" >-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5018a_level0_row19\" class=\"row_heading level0 row19\" >baichuan-13b-chat</th>\n",
       "      <td id=\"T_5018a_row19_col0\" class=\"data row19 col0\" >1727</td>\n",
       "      <td id=\"T_5018a_row19_col1\" class=\"data row19 col1\" >2.0</td>\n",
       "      <td id=\"T_5018a_row19_col2\" class=\"data row19 col2\" >2.6</td>\n",
       "      <td id=\"T_5018a_row19_col3\" class=\"data row19 col3\" >0.6</td>\n",
       "      <td id=\"T_5018a_row19_col4\" class=\"data row19 col4\" >-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b5636090>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting.show_new_lb(lb, \"avg_sigmoid_length_corrected_win_rate\", n=15, n_tail=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579bb55-0c8a-412b-80cf-7b5174576b1d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5be47d1b-448c-44b9-87f7-193f9303f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arena Correlation (↑)</th>\n",
       "      <th>Gameability (↓)</th>\n",
       "      <th>Adversarial Win Rate Gain (↓)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Win Rate</th>\n",
       "      <td>0.94</td>\n",
       "      <td>26%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length-Controlled Win Rate</th>\n",
       "      <td>0.98</td>\n",
       "      <td>10%</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length-Normalized Win Rate</th>\n",
       "      <td>0.96</td>\n",
       "      <td>15%</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length-Balanced Win Rate</th>\n",
       "      <td>0.95</td>\n",
       "      <td>15%</td>\n",
       "      <td>40.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Arena Correlation (↑) Gameability (↓)  \\\n",
       "Win Rate                                    0.94             26%   \n",
       "Length-Controlled Win Rate                  0.98             10%   \n",
       "Length-Normalized Win Rate                  0.96             15%   \n",
       "Length-Balanced Win Rate                    0.95             15%   \n",
       "\n",
       "                           Adversarial Win Rate Gain (↓)  \n",
       "Win Rate                                             0.0  \n",
       "Length-Controlled Win Rate                           8.5  \n",
       "Length-Normalized Win Rate                           3.6  \n",
       "Length-Balanced Win Rate                            40.8  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = pd.concat([pd.Series(raw_metrics), pd.Series(lc_metrics),pd.Series(normalized_metrics) , pd.Series(balanced_metrics)], axis=1,\n",
    "          keys=[\"Win Rate\", \"Length-Controlled Win Rate\", \"Length-Normalized Win Rate\", \"Length-Balanced Win Rate\"]\n",
    "         )\n",
    "\n",
    "all_metrics.loc[\"Arena Correlation (↑)\"] = [f\"{g:.2f}\" for g in all_metrics.loc[\"corr_arena\"]]\n",
    "all_metrics.loc[\"Gameability (↓)\"] = [f\"{g:.0f}%\" for g in (all_metrics.loc[\"verbosity_gameability\"] + all_metrics.loc[\"conciseness_gameability\"])/2]\n",
    "all_metrics.loc[\"Adversarial Win Rate Gain (↓)\"] = [f\"{g:.1f}\" for g in all_metrics.loc[\"adversarial_winrate_gain\"]]\n",
    "all_metrics = all_metrics.loc[[\"Arena Correlation (↑)\", \"Gameability (↓)\", \"Adversarial Win Rate Gain (↓)\"], :].T\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d1fc41bc-2066-4f14-b890-adf1bada3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(all_metrics, filename=\"figures/all_metrics_length.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
